# 3_ğŸ§­_SuÃ§_Tahmini.py
# Tek sayfa: tarih/saat(veya gÃ¼n/aralÄ±k) + kategori + GEOID filtreleriyle sonuÃ§larÄ± listeler/grafikler.
# ZIP/URL/yerel parquet okuma destekli. Actions artifact (token) > Release fallback.

import os
import io
import zipfile
import posixpath
from io import BytesIO
from datetime import datetime, timedelta

import requests
import pandas as pd
import numpy as np
import streamlit as st

# ---------------------------
# Sayfa ayarÄ±
# ---------------------------
st.set_page_config(
    page_title="SuÃ§ Tahmini",
    page_icon="ğŸŒ€",
    layout="wide",
)

# ---------------------------
# Kaynak Ã§Ã¶zÃ¼mleyici: Actions artifact -> Release fallback
# ---------------------------
REPO_OWNER = "cem5113"
REPO_NAME  = "crime_prediction_data"
RELEASE_ASSET_ZIP = "fr-crime-outputs-parquet.zip"  # varsa release asset adÄ±

def _resolve_artifact_zip_url(owner: str, repo: str, name_contains: str, token: str | None):
    """Repo'daki en gÃ¼ncel, sÃ¼resi dolmamÄ±ÅŸ artifact ZIP linkini dÃ¶ndÃ¼rÃ¼r (URL, headers)."""
    if not token:
        return None, {}
    base = f"https://api.github.com/repos/{owner}/{repo}"
    r = requests.get(
        f"{base}/actions/artifacts?per_page=100",
        headers={"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"},
        timeout=60,
    )
    r.raise_for_status()
    arts = (r.json() or {}).get("artifacts", []) or []
    arts = [a for a in arts if (name_contains in (a.get("name",""))) and not a.get("expired")]
    if not arts:
        return None, {}
    art = sorted(arts, key=lambda a: a.get("created_at",""), reverse=True)[0]
    zip_url = f"{base}/actions/artifacts/{art['id']}/zip"
    headers = {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"}
    return zip_url, headers

def _best_zip_url():
    """
    1) Actions artifact (token varsa)
    2) Release fallback (yoksa)
    """
    token = os.getenv("GITHUB_TOKEN") or os.getenv("GH_TOKEN") or os.getenv("github_token")
    url, headers = _resolve_artifact_zip_url(REPO_OWNER, REPO_NAME, "fr-crime-outputs-parquet", token)
    if url:
        return url, headers
    rel = f"https://github.com/{REPO_OWNER}/{REPO_NAME}/releases/latest/download/{RELEASE_ASSET_ZIP}"
    return rel, {}

# ---------------------------
# ZIP/URL/yerel akÄ±llÄ± okuyucu
# ---------------------------
def _read_parquet_from_zip_bytes(zip_bytes: bytes, member_path: str) -> pd.DataFrame:
    """
    Bir ZIP'in iÃ§indeki 'member_path'i Parquet olarak okur.
    - DoÄŸrudan eÅŸleÅŸme
    - Basename ile klasÃ¶r iÃ§inden bulma
    - Ä°Ã§ ZIP'lerde (.zip) arama (Ã¶r. fr_parquet_outputs.zip)
    - artifact/ altÄ±nÄ± destekler
    """
    target_base = posixpath.basename(member_path)

    with zipfile.ZipFile(BytesIO(zip_bytes)) as z:
        names = z.namelist()

        # 1) DoÄŸrudan arama
        if member_path in names:
            with z.open(member_path) as f:
                return pd.read_parquet(BytesIO(f.read()))

        # 1.b) Basename ile eÅŸleÅŸen ilk dosya (klasÃ¶r farketmez)
        cand = [n for n in names if n.endswith("/"+target_base) or n == target_base]
        if cand:
            with z.open(cand[0]) as f:
                return pd.read_parquet(BytesIO(f.read()))

        # 2) Ä°Ã§ ZIP'ler
        for nested in names:
            if not nested.lower().endswith(".zip"):
                continue
            with z.open(nested) as fz:
                with zipfile.ZipFile(BytesIO(fz.read())) as z2:
                    inner = z2.namelist()
                    if member_path in inner:
                        with z2.open(member_path) as f2:
                            return pd.read_parquet(BytesIO(f2.read()))
                    cand2 = [m for m in inner if m.endswith("/"+target_base) or m == target_base]
                    if cand2:
                        with z2.open(cand2[0]) as f2:
                            return pd.read_parquet(BytesIO(f2.read()))

    raise FileNotFoundError(f"ZIP iÃ§inde bulunamadÄ±: {member_path}")

def read_parquet_smart(spec: str) -> pd.DataFrame:
    """
    spec biÃ§imleri:
      - Yerel parquet:        /path/to/file.parquet
      - Yerel zip iÃ§i:        zip::/path/to/file.zip::artifact/risk_hourly.parquet
      - URL zip iÃ§i:          urlzip::<URL veya AUTO>::artifact/risk_hourly.parquet
      - URL iÃ§ ZIPâ€™in iÃ§i:    urlzip::<URL veya AUTO>::fr_crime_09.parquet  (iÃ§ ZIP de taranÄ±r)
    """
    if spec.startswith("urlzip::"):
        url, member = spec[len("urlzip::"):].split("::", 1)
        headers = {}
        if url == "AUTO":  # artifact->release otomatik
            url, headers = _best_zip_url()
        r = requests.get(url, headers=headers, timeout=120, allow_redirects=True)
        r.raise_for_status()
        return _read_parquet_from_zip_bytes(r.content, member)

    elif spec.startswith("zip::"):
        zip_path, member = spec[len("zip::"):].split("::", 1)
        if not os.path.exists(zip_path):
            raise FileNotFoundError(f"ZIP yok: {zip_path}")
        with open(zip_path, "rb") as f:
            return _read_parquet_from_zip_bytes(f.read(), member)

    else:
        # dÃ¼z parquet
        if not os.path.exists(spec):
            raise FileNotFoundError(f"Dosya yok: {spec}")
        return pd.read_parquet(spec)

# ---------------------------
# YardÄ±mcÄ±lar
# ---------------------------
@st.cache_data(show_spinner=False)
def load_hourly(path: str) -> pd.DataFrame:
    df = read_parquet_smart(path)
    # Beklenen kolonlar: timestamp, geoid, category, p_stack
    if "timestamp" not in df.columns:
        if "datetime" in df.columns:
            df = df.rename(columns={"datetime": "timestamp"})
        else:
            raise ValueError("Saatlik tabloda 'timestamp' ya da 'datetime' kolonu yok.")
    df["timestamp"] = pd.to_datetime(df["timestamp"], utc=False)

    if "geoid" not in df.columns and "GEOID" in df.columns:
        df = df.rename(columns={"GEOID": "geoid"})
    df["geoid"] = df["geoid"].astype(str)

    if "category" not in df.columns:
        df["category"] = "Genel"
    else:
        df["category"] = df["category"].astype(str)

    if "p_stack" not in df.columns:
        raise ValueError("Beklenen kolon 'p_stack' (stacking olasÄ±lÄ±ÄŸÄ±) bulunamadÄ±.")
    return df

@st.cache_data(show_spinner=False)
def load_daily(path: str) -> pd.DataFrame | None:
    try:
        df = read_parquet_smart(path)
    except Exception:
        return None

    if "date" not in df.columns:
        ts_col = "timestamp" if "timestamp" in df.columns else ("datetime" if "datetime" in df.columns else None)
        if ts_col is not None:
            dt = pd.to_datetime(df[ts_col], errors="coerce", utc=False)
            if dt.notna().any():
                df["date"] = dt.dt.floor("D")
    else:
        df["date"] = pd.to_datetime(df["date"], errors="coerce", utc=False)

    return df

def filter_by_time(df: pd.DataFrame, mode: str,
                   ts: datetime | None,
                   day: datetime | None,
                   start: datetime | None,
                   end: datetime | None) -> pd.DataFrame:
    if mode == "Tek saat":
        if ts is None:
            return df.iloc[0:0]
        return df[df["timestamp"] == pd.to_datetime(ts)]
    elif mode == "GÃ¼n (24 saat)":
        if day is None:
            return df.iloc[0:0]
        t0 = pd.to_datetime(day).replace(hour=0, minute=0, second=0, microsecond=0)
        t1 = t0 + timedelta(days=1)
        return df[(df["timestamp"] >= t0) & (df["timestamp"] < t1)]
    else:  # "AralÄ±k"
        if not (start and end):
            return df.iloc[0:0]
        t0 = pd.to_datetime(start)
        t1 = pd.to_datetime(end)
        return df[(df["timestamp"] >= t0) & (df["timestamp"] <= t1)]

def df_to_csv_bytes(df: pd.DataFrame) -> bytes:
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    return buf.getvalue().encode("utf-8")

# ---------------------------
# VarsayÄ±lan yollar (AUTO: artifact -> release)
# ---------------------------
# Saatlik skorlar (artifact/risk_hourly.parquet)
DEFAULT_HOURLY = "urlzip::AUTO::artifact/risk_hourly.parquet"

# Opsiyonel gÃ¼nlÃ¼k/Ã¶zet â€“ en zengin tablo (fr_crime_09.parquet)
DEFAULT_DAILY  = "urlzip::AUTO::fr_crime_09.parquet"

# ---------------------------
# Sidebar â€” seÃ§imler
# ---------------------------
st.sidebar.header("âš™ï¸ Ayarlar")

hourly_path = st.sidebar.text_input(
    "Saatlik Ã§Ä±ktÄ± dosyasÄ± (ZIP/URL/yerel destekli)",
    value=DEFAULT_HOURLY,
    help=(
        "Ã–rnekler:\n"
        "- URL ZIP (AUTO): urlzip::AUTO::artifact/risk_hourly.parquet\n"
        "- Yerel ZIP: zip::/path/to/fr-crime-outputs-parquet.zip::artifact/risk_hourly.parquet\n"
        "- DÃ¼z parquet: /path/to/risk_hourly.parquet"
    ),
)
daily_path  = st.sidebar.text_input(
    "(Opsiyonel) GÃ¼nlÃ¼k/Ã¶zet dosyasÄ±",
    value=DEFAULT_DAILY,
    help=(
        "Ã–rnekler:\n"
        "- URL ZIP (AUTO): urlzip::AUTO::fr_crime_09.parquet\n"
        "- Yerel ZIP: zip::/path/to/fr-crime-outputs-parquet.zip::fr_crime_09.parquet\n"
        "- DÃ¼z parquet: /path/to/risk_daily_by_category.parquet"
    ),
)

# Veri yÃ¼kle
try:
    df = load_hourly(hourly_path)
except Exception as e:
    st.error(f"Saatlik dosya okunamadÄ±:\n\n{e}")
    # Token yoksa kÄ±sa ipucu:
    st.info("Ä°pucu: Artifact iÃ§in ortamda GITHUB_TOKEN/GH_TOKEN/github_token bulunmalÄ±. "
            "Yoksa Release fallback denenir.")
    st.stop()

df_daily = load_daily(daily_path)

# ---------------------------
# Zaman modu & seÃ§imler
# ---------------------------
time_mode = st.sidebar.radio("Zaman seÃ§imi", ["Tek saat", "GÃ¼n (24 saat)", "AralÄ±k"], horizontal=False)

ts_single = day_single = start_range = end_range = None
if time_mode == "Tek saat":
    ts_candidates = sorted(pd.to_datetime(df["timestamp"]).unique())
    default_idx = 0 if len(ts_candidates) > 0 else None
    ts_single = st.sidebar.selectbox("Zaman (timestamp)", options=ts_candidates, index=default_idx) if len(ts_candidates) else None
elif time_mode == "GÃ¼n (24 saat)":
    days = sorted(pd.to_datetime(df["timestamp"]).dt.date.unique())
    default_idx = 0 if len(days) > 0 else None
    day_single = st.sidebar.selectbox("GÃ¼n", options=days, index=default_idx) if len(days) else None
else:
    ts_all = sorted(pd.to_datetime(df["timestamp"]).unique())
    if ts_all:
        start_range = st.sidebar.selectbox("BaÅŸlangÄ±Ã§", options=ts_all, index=0)
        end_range   = st.sidebar.selectbox("BitiÅŸ", options=ts_all, index=len(ts_all)-1)
    else:
        st.sidebar.info("UyarÄ±: Saatlik veri boÅŸ gÃ¶rÃ¼nÃ¼yor.")

# Kategori & GEOID seÃ§imleri
cats = sorted(df["category"].astype(str).unique().tolist())
geoids = sorted(df["geoid"].astype(str).unique().tolist())

sel_cats = st.sidebar.multiselect("SuÃ§ kategorileri", options=cats, default=cats)
scope_choice = st.sidebar.radio("Alan", ["TÃ¼m ÅŸehir", "GEOID seÃ§"], horizontal=True)
if scope_choice == "GEOID seÃ§":
    sel_geoids = st.sidebar.multiselect("GEOID", options=geoids, default=geoids[:20])
else:
    sel_geoids = geoids  # hepsi

# GÃ¶rÃ¼nÃ¼m seÃ§enekleri
agg_daily_how = st.sidebar.selectbox("GÃ¼nlÃ¼k agregasyon (gÃ¶rÃ¼nÃ¼m)", ["Ortalama", "Maksimum"], index=0)
top_k = st.sidebar.slider("Top-K sÄ±ralama (tablo)", min_value=10, max_value=200, value=50, step=10)
risk_cut = st.sidebar.slider("Risk eÅŸiÄŸi (vurgulama)", min_value=0.0, max_value=1.0, value=0.5, step=0.05)

# ---------------------------
# Ä°Ã§erik â€” baÅŸlÄ±k
# ---------------------------
st.title("ğŸŒ€ SuÃ§ Tahmini")
st.caption("Zamanâ€“mekÃ¢nâ€“suÃ§ tÃ¼rÃ¼ bazlÄ± olasÄ±lÄ±k tahmini (stacking ensemble).")

# ---------------------------
# Filtrele
# ---------------------------
df_t = filter_by_time(df, time_mode, ts_single, day_single, start_range, end_range)
if sel_cats:
    df_t = df_t[df_t["category"].isin(sel_cats)]
if sel_geoids:
    df_t = df_t[df_t["geoid"].isin(sel_geoids)]

# ---------------------------
# Ã–zet kartlarÄ±
# ---------------------------
c1, c2, c3, c4 = st.columns(4)
c1.metric("Kapsanan saat sayÄ±sÄ±", f"{df_t['timestamp'].nunique():,}")
c2.metric("GEOID sayÄ±sÄ±", f"{df_t['geoid'].nunique():,}")
c3.metric("Kategori sayÄ±sÄ±", f"{df_t['category'].nunique():,}")
if len(df_t):
    c4.metric("Ortalama risk", f"{df_t['p_stack'].mean():.3f}")
else:
    c4.metric("Ortalama risk", "â€”")

# ---------------------------
# GÃ¶rÃ¼nÃ¼mler
# ---------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ” Top-K tablo", "ğŸ“ˆ Zaman serisi", "ğŸ“Š Kategori/GEOID Ã¶zet"])

# --- Top-K tablo ---
with tab1:
    if time_mode == "Tek saat":
        show_df = (
            df_t.sort_values("p_stack", ascending=False)
                .head(top_k)
                .reset_index(drop=True)
        )
        st.subheader("Top-K (tek saat)")
        st.dataframe(
            show_df.style.highlight_between(subset="p_stack", left=risk_cut, right=1.0, color="#ffd6cc"),
            use_container_width=True, height=520
        )
    else:
        # Ã‡ok saat kapsÄ±yorsa, geoÃ—cat Ã¶zete indir
        show_df = (
            df_t.groupby(["geoid", "category"], as_index=False)
                .agg(mean_risk=("p_stack", "mean"),
                     max_risk=("p_stack", "max"),
                     n_hours=("p_stack", "size"))
        )
        order_col = "mean_risk" if agg_daily_how == "Ortalama" else "max_risk"
        show_df = show_df.sort_values(order_col, ascending=False).head(top_k).reset_index(drop=True)
        st.subheader(f"Top-K (aralÄ±k/gÃ¼n) â€” {order_col}")
        st.dataframe(
            show_df.style.highlight_between(subset=order_col, left=risk_cut, right=1.0, color="#ffd6cc"),
            use_container_width=True, height=520
        )

    # Ä°ndir
    st.download_button(
        "â¬‡ï¸ CSV indir (gÃ¶sterilen)",
        data=df_to_csv_bytes(show_df),
        file_name="crime_forecast_topk.csv",
        mime="text/csv"
    )

# --- Zaman serisi ---
with tab2:
    if len(df_t) == 0:
        st.info("SeÃ§ilen zaman/kapsam iÃ§in veri yok.")
    else:
        geo_for_plot = st.multiselect(
            "Grafik iÃ§in GEOID seÃ§",
            options=sorted(df_t["geoid"].unique().tolist()),
            default=sorted(df_t["geoid"].unique().tolist())[:3]
        )
        df_plot = df_t[df_t["geoid"].isin(geo_for_plot)].copy()
        st.line_chart(
            df_plot.pivot_table(index="timestamp", columns="geoid", values="p_stack", aggfunc="mean").sort_index(),
            height=420
        )

# --- Kategori/GEOID Ã¶zet ---
with tab3:
    if len(df_t) == 0:
        st.info("SeÃ§ilen zaman/kapsam iÃ§in veri yok.")
    else:
        cA, cB = st.columns(2)
        # Kategori ortalamalarÄ±
        cat_summary = (
            df_t.groupby("category", as_index=False)["p_stack"].mean()
                .sort_values("p_stack", ascending=False)
        )
        cA.subheader("Kategori ortalama risk")
        cA.bar_chart(cat_summary.set_index("category"), height=300)

        # GEOID ortalamalarÄ± (ilk 20)
        geo_summary = (
            df_t.groupby("geoid", as_index=False)["p_stack"].mean()
                .sort_values("p_stack", ascending=False)
                .head(20)
        )
        cB.subheader("GEOID ortalama risk (Top-20)")
        cB.bar_chart(geo_summary.set_index("geoid"), height=300)

# ---------------------------
# GÃ¼nlÃ¼k/Ã¶zet gÃ¶rÃ¼nÃ¼m (opsiyonel)
# ---------------------------
st.markdown("---")
st.subheader("ğŸ“… GÃ¼nlÃ¼k Ã¶zet (opsiyonel)")

def _has_daily_view_cols(d: pd.DataFrame) -> bool:
    return ("date" in d.columns) and ("daily_score" in d.columns)

df_daily = df_daily  # zaten yÃ¼klendi
if df_daily is None:
    st.caption("`fr_crime_09.parquet` (veya `risk_daily_by_category.parquet`) bulunamadÄ±/okunamadÄ± â€” opsiyonel bÃ¶lÃ¼mdÃ¼r.")
else:
    if _has_daily_view_cols(df_daily):
        days_all = sorted(pd.to_datetime(df_daily["date"]).unique())
        idx = len(days_all)-1 if len(days_all) else 0
        day_sel = st.selectbox("GÃ¼n seÃ§", options=days_all, index=idx if len(days_all) else None)
        d1 = df_daily[pd.to_datetime(df_daily["date"]) == pd.to_datetime(day_sel)]
        if sel_cats:
            d1 = d1[d1["category"].astype(str).isin(sel_cats)]
        if sel_geoids:
            d1 = d1[d1["geoid"].astype(str).isin(sel_geoids)]
        st.dataframe(
            d1.sort_values("daily_score", ascending=False).head(top_k).reset_index(drop=True),
            use_container_width=True, height=360
        )
    else:
        st.caption("GÃ¼nlÃ¼k Ã¶zet iÃ§in gerekli kolonlar bulunamadÄ± (`date` + `daily_score`). Bu bÃ¶lÃ¼m bilgi amaÃ§lÄ±dÄ±r ve zorunlu deÄŸildir.")

# ---------------------------
# Dipnot
# ---------------------------
st.caption(
    "Model: Ã¼Ã§ motorlu stacking (short/mid) + mevsimsel baseline (long). "
    "OlasÄ±lÄ±klar kalibre edilmiÅŸtir (isotonic). `confidence` ufka gÃ¶re azaltÄ±lmÄ±ÅŸ gÃ¼ven skorunu ifade eder."
)
