import streamlit as st
import pandas as pd
import geopandas as gpd
import folium
from streamlit_folium import st_folium

# --- 1. Veri yÃ¼kleme ---
# KullanÄ±lacak veri: cem5113/crime_prediction_data/artifact/fr-crime-pipeline-output.zip iÃ§indeki fr_crime_09.csv
# Stacking metrikleri: cem5113/crime_prediction_data/artifact/sf-crime-pipeline-output.zip iÃ§indeki metrics_stacking_ohe.csv

@st.cache_data
def load_data():
    import io, zipfile, requests, pandas as pd

    RAW_FR_CSV = (
        "https://github.com/cem5113/crime_prediction_data/raw/main/"
        "artifact/fr-crime-pipeline-output/fr_crime_09.csv"
    )
    RAW_METRICS_CSV = (
        "https://github.com/cem5113/crime_prediction_data/raw/main/"
        "artifact/sf-crime-pipeline-output/metrics_stacking_ohe.csv"
    )

    # Repo iÃ§i ZIP dosyalarÄ±
    ZIP_FR_RAW = "https://github.com/cem5113/crime_prediction_data/raw/main/artifact/fr-crime-pipeline-output.zip"
    ZIP_SF_RAW = "https://github.com/cem5113/crime_prediction_data/raw/main/artifact/sf-crime-pipeline-output.zip"

    # Releases ZIP dosyalarÄ±
    ZIP_FR_REL = "https://github.com/cem5113/crime_prediction_data/releases/latest/download/fr-crime-pipeline-output.zip"
    ZIP_SF_REL = "https://github.com/cem5113/crime_prediction_data/releases/latest/download/sf-crime-pipeline-output.zip"

    # â†“ CSVâ€™yi veya ZIPâ€™ten iÃ§eriÄŸi oku â†“
    df = None
    metrics = None

    try:
        df = pd.read_csv(RAW_FR_CSV)
    except Exception:
        for url in [ZIP_FR_RAW, ZIP_FR_REL]:
            try:
                r = requests.get(url, timeout=60)
                r.raise_for_status()
                with zipfile.ZipFile(io.BytesIO(r.content)) as zf:
                    for name in zf.namelist():
                        if name.endswith("fr_crime_09.csv"):
                            with zf.open(name) as f:
                                df = pd.read_csv(f)
                            break
                if df is not None:
                    break
            except Exception:
                pass
        if df is None:
            raise FileNotFoundError("fr_crime_09.csv bulunamadÄ±")

    try:
        metrics = pd.read_csv(RAW_METRICS_CSV)
    except Exception:
        for url in [ZIP_SF_RAW, ZIP_SF_REL]:
            try:
                r = requests.get(url, timeout=60)
                r.raise_for_status()
                with zipfile.ZipFile(io.BytesIO(r.content)) as zf:
                    for name in zf.namelist():
                        if name.endswith("metrics_stacking_ohe.csv"):
                            with zf.open(name) as f:
                                metrics = pd.read_csv(f)
                            break
                if metrics is not None:
                    break
            except Exception:
                pass
        if metrics is None:
            raise FileNotFoundError("metrics_stacking_ohe.csv bulunamadÄ±")

    return df, metrics

df, metrics = load_data()

# --- 2. ArayÃ¼z BaÅŸlÄ±ÄŸÄ± ---
st.title('ğŸ” SuÃ§ Tahmin ModÃ¼lÃ¼ (YalnÄ±z KolluÄŸa YararlÄ±)')
st.markdown('Zaman, mekÃ¢n ve kategori bazlÄ± risk tahminleri â€” yalnÄ±z kolluk iÃ§in anlamlÄ± sonuÃ§lar gÃ¶sterilir.')

# --- 3. Filtreler ---
col1, col2, col3 = st.columns(3)
with col1:
    date_selected = st.date_input('Tarih seÃ§in')
with col2:
    hour_selected = st.slider('Saat aralÄ±ÄŸÄ± seÃ§in', 0, 23, (18, 23))
with col3:
    category_selected = st.selectbox('SuÃ§ kategorisi', sorted(df['Category'].dropna().unique()))

show_only_relevant = st.toggle('ğŸ”’ YalnÄ±z kolluÄŸa yararlÄ± sonuÃ§larÄ± gÃ¶ster', value=True)

# --- 4. Risk Filtreleme ---
if 'risk_score' in df.columns:
    q75 = df['risk_score'].quantile(0.75)
else:
    st.warning('âš ï¸ Veri kÃ¼mesinde risk_score sÃ¼tunu bulunamadÄ±. risk olasÄ±lÄ±ÄŸÄ± hesaplanmalÄ±.')
    q75 = 0.5

filtered = df[df['risk_score'] >= q75] if show_only_relevant else df

# Saat ve kategori filtreleme
if 'hour' in df.columns:
    filtered = filtered[(filtered['hour'] >= hour_selected[0]) & (filtered['hour'] <= hour_selected[1])]
if category_selected:
    filtered = filtered[filtered['Category'] == category_selected]

# --- 5. Harita OluÅŸturma ---
center = [37.77, -122.42]
m = folium.Map(location=center, zoom_start=12, tiles='CartoDB positron')

for _, row in filtered.iterrows():
    if 'latitude' in row and 'longitude' in row:
        popup_text = f"GEOID: {row['GEOID']}<br>Risk: {row['risk_score']:.2f}<br>Saat: {row['hour']}<br>Kategori: {row['Category']}"
        color = 'red' if row['risk_score'] >= q75 else 'orange'
        folium.CircleMarker(
            location=[row['latitude'], row['longitude']],
            radius=6,
            color=color,
            fill=True,
            fill_opacity=0.7,
            popup=popup_text
        ).add_to(m)

st_folium(m, width=750, height=550)

# --- 6. Ã–zet Tablo ---
st.subheader('ğŸ“Š YÃ¼ksek Riskli Noktalar')
st.dataframe(filtered[['GEOID', 'hour', 'Category', 'risk_score']].sort_values(by='risk_score', ascending=False).head(20))

# --- 7. Stacking Performans Ã–zeti ---
st.subheader('ğŸ“ˆ Model Performans Ã–zeti (Stacking)')
st.dataframe(metrics)

# --- 8. Veri DÄ±ÅŸa AktarÄ±m ---
st.download_button('â¬‡ï¸ Hotspot verisini indir (CSV)', filtered.to_csv(index=False), 'high_risk_hotspots.csv', 'text/csv')
