# 3_ğŸ§­_SuÃ§_Tahmini â€” HaritalÄ± gÃ¶rÃ¼nÃ¼m (GEOID + centroid) 
# 3 Saatlik Bloklar (â‰¤7 gÃ¼n; 3-saatlik aralÄ±k) ve GÃ¼nlÃ¼k (â‰¤365 gÃ¼n) risk gÃ¶rÃ¼nÃ¼mleri
# Kaynak: artifact 'fr-crime-outputs-parquet' â†’ risk_hourly_next24h_top3 / risk_daily_next365d_top5
# Not: Harita iÃ§in centroid yalnÄ±zca artifact iÃ§indeki adaylardan bulunur (upload yok).

import os
from streamlit_folium import st_folium
import folium
import io
import json
import posixpath
import zipfile
from io import BytesIO
from datetime import datetime, timedelta

try:
    from zoneinfo import ZoneInfo
except Exception:
    ZoneInfo = None

import requests
import pandas as pd
import numpy as np
import streamlit as st
import pydeck as pdk

# ------------------------------------------------------------
# âš™ï¸ GitHub repo ve artifact bilgisi
# ------------------------------------------------------------
REPOSITORY_OWNER = "cem5113"
REPOSITORY_NAME  = "crime_prediction_data"
ARTIFACT_NAME_SHOULD_CONTAIN = "fr-crime-outputs-parquet"  # FR risk Ã§Ä±ktÄ±larÄ± artifact'i

# Artifact iÃ§indeki beklenen dosyalar (FR pipeline risk Ã§Ä±ktÄ±larÄ±)
ARTIFACT_MEMBER_HOURLY = "risk_3h_next7d_top3"
ARTIFACT_MEMBER_DAILY  = "risk_daily_next365d_top5"

# ğŸ” Yeni 3-saatlik CSV (FR style) iÃ§in yerel yol
CSV_HOURLY_FRSTYLE = "data/crime_forecast_7days_all_geoids_FRstyle.csv"

# Yerel GeoJSON (2_ğŸ—ºï¸_Risk_HaritasÄ±.py ile aynÄ±)
GEOJSON_LOCAL = "data/sf_cells.geojson"

# ------------------------------------------------------------
# ğŸ”‘ Token / Header
# ------------------------------------------------------------
def resolve_github_token() -> str | None:
    if os.getenv("GITHUB_TOKEN"):
        return os.getenv("GITHUB_TOKEN")
    for key in ("github_token", "GH_TOKEN", "GITHUB_TOKEN"):
        try:
            if key in st.secrets and st.secrets[key]:
                os.environ["GITHUB_TOKEN"] = str(st.secrets[key])
                return os.environ["GITHUB_TOKEN"]
        except Exception:
            pass
    return None

def github_api_headers() -> dict:
    headers = {"Accept": "application/vnd.github+json"}
    token = os.getenv("GITHUB_TOKEN")
    if token:
        headers["Authorization"] = f"Bearer {token}"
    return headers

# ------------------------------------------------------------
# ğŸ“¦ Artifact ZIP alma (en gÃ¼ncel ve sÃ¼resi dolmamÄ±ÅŸ)
# ------------------------------------------------------------
def resolve_latest_artifact_zip_url(owner: str, repo: str, name_contains: str):
    token = resolve_github_token()
    if not token:
        return None, {}
    base = f"https://api.github.com/repos/{owner}/{repo}"
    response = requests.get(
        f"{base}/actions/artifacts?per_page=100",
        headers=github_api_headers(),
        timeout=60,
    )
    response.raise_for_status()
    artifacts = (response.json() or {}).get("artifacts", []) or []
    artifacts = [
        a for a in artifacts
        if (name_contains in a.get("name", "")) and not a.get("expired")
    ]
    if not artifacts:
        return None, {}
    artifacts.sort(key=lambda a: a.get("updated_at", ""), reverse=True)
    url = f"{base}/actions/artifacts/{artifacts[0]['id']}/zip"
    return url, github_api_headers()

# ------------------------------------------------------------
# ğŸ§° ZIP iÃ§inden Ã¼ye okuma (nested zip + parquet/csv fallback)
# ------------------------------------------------------------
def read_member_from_zip_bytes(zip_bytes: bytes, member_path: str) -> pd.DataFrame:
    """
    Artifact ZIP'inde:
      - Ã¶nce doÄŸrudan dosyayÄ± arar
      - yoksa iÃ§erdeki .zip (Ã¶rn. fr_parquet_outputs.zip) dosyalarÄ±nÄ± aÃ§Ä±p orada arar.

    member_path: "risk_hourly_next24h_top3" gibi gÃ¶vde adÄ±.
    """

    def read_any_table(raw_bytes: bytes, name_hint: str) -> pd.DataFrame:
        buf = BytesIO(raw_bytes)
        name_l = name_hint.lower()
        if name_l.endswith(".csv"):
            return pd.read_csv(buf)
        # Ã–nce parquet dene, hata olursa csv'e dÃ¼ÅŸ
        try:
            buf.seek(0)
            return pd.read_parquet(buf)
        except Exception:
            buf.seek(0)
            return pd.read_csv(buf)

    def scan_zip(zf: zipfile.ZipFile, member_path: str) -> pd.DataFrame | None:
        """Verilen ZipFile iÃ§inde stem'i geÃ§en ilk dosyayÄ± bulup DataFrame dÃ¶ndÃ¼rÃ¼r."""
        names = zf.namelist()
        base  = posixpath.basename(member_path)
        stem  = base.split(".")[0]
        stemL = stem.lower()

        for n in names:
            bn = posixpath.basename(n)
            if stemL in bn.lower():
                with zf.open(n) as f:
                    return read_any_table(f.read(), bn)
        return None

    # 1) DÄ±ÅŸ ZIP'i aÃ§
    with zipfile.ZipFile(BytesIO(zip_bytes)) as outer:
        # Ã–nce dÄ±ÅŸ zip iÃ§inde ara
        df = scan_zip(outer, member_path)
        if df is not None:
            return df

        # 2) Bulunamazsa: iÃ§erdeki .zip dosyalarÄ±nÄ± sÄ±rayla dene (Ã¶rneÄŸin fr_parquet_outputs.zip)
        for name in outer.namelist():
            if name.lower().endswith(".zip"):
                with outer.open(name) as f_z:
                    inner_bytes = f_z.read()
                try:
                    with zipfile.ZipFile(BytesIO(inner_bytes)) as inner:
                        df_inner = scan_zip(inner, member_path)
                        if df_inner is not None:
                            return df_inner
                except zipfile.BadZipFile:
                    continue

    # HiÃ§bir eÅŸleÅŸme bulunamadÄ±ysa:
    raise FileNotFoundError(
        f"ZIP iÃ§inde '{member_path}' gÃ¶vdesini iÃ§eren bir CSV/PARQUET dosyasÄ± bulunamadÄ±."
    )

@st.cache_data(show_spinner=False)
def load_artifact_member(member: str) -> pd.DataFrame:
    url, headers = resolve_latest_artifact_zip_url(
        REPOSITORY_OWNER, REPOSITORY_NAME, ARTIFACT_NAME_SHOULD_CONTAIN
    )
    if not url:
        raise RuntimeError("Artifact bulunamadÄ± veya GITHUB_TOKEN yok.")
    r = requests.get(url, headers=headers, timeout=120, allow_redirects=True)
    r.raise_for_status()
    return read_member_from_zip_bytes(r.content, member)

# ------------------------------------------------------------
# ğŸ§­ Åema doÄŸrulayÄ±cÄ±lar (hourly/daily)
#    NOT: ArtÄ±k tÃ¼m FR kolonlarÄ± korunuyor, sadece zorunlu
#         kolonlar normalize ediliyor.
# ------------------------------------------------------------
def normalize_hourly_schema(df: pd.DataFrame) -> pd.DataFrame:
    """
    risk_3h_next7d_top3 veya crime_forecast_7days_all_geoids_FRstyle.csv iÃ§in
    saatlik (3-saatlik blok) ÅŸema normalizasyonu.

    Desteklenen kolonlar:
      - date
      - geoid
      - risk_score / p_stack / prob / probability / score / risk
      - hour  veya  hour_range_3h / hour_range / hour_block

    EÄŸer hour yoksa, hour_range_3h iÃ§inden baÅŸlangÄ±Ã§ saati (0,3,6,...) Ã§Ä±karÄ±lÄ±r
    ve 'hour' kolonuna yazÄ±lÄ±r. 'timestamp' = date + hour (saat) olarak Ã¼retilir.
    """
    df = df.copy()
    cols = {c.lower(): c for c in df.columns}

    def pick(*names):
        for n in names:
            if n in df.columns:
                return n
            if n.lower() in cols:
                return cols[n.lower()]
        return None

    c_date   = pick("date")
    c_hour   = pick("hour", "hour_idx", "hour_of_day", "hour_index")
    c_hrange = pick("hour_range_3h", "hour_range", "hour_block")
    c_geoid  = pick("geoid", "GEOID", "cell_id", "id")
    c_risk   = pick("risk_score", "p_stack", "prob", "probability", "score", "risk")

    if not (c_date and c_geoid and c_risk and (c_hour or c_hrange)):
        raise ValueError(
            "Saatlik veri iÃ§in 'date, geoid, risk_score' ve 'hour' veya "
            "'hour_range_3h' benzeri bir kolon zorunlu."
        )

    # Tarih
    df["date"] = pd.to_datetime(df[c_date], errors="coerce")

    # GEOID ve risk skoru
    df["geoid"] = df[c_geoid].astype(str)
    df["risk_score"] = pd.to_numeric(df[c_risk], errors="coerce")

    # Saat: varsa doÄŸrudan 'hour', yoksa hour_range_3h iÃ§inden baÅŸlangÄ±Ã§ saati
    if c_hour:
        df["hour"] = (
            pd.to_numeric(df[c_hour], errors="coerce")
            .astype("Int64")
            .clip(0, 23)
        )
    else:
        def parse_start_hour(val) -> float:
            if pd.isna(val):
                return np.nan
            s = str(val).strip()
            # farklÄ± tire karakterlerini normalize et
            s = s.replace("â€“", "-").replace("â€”", "-")
            if "-" not in s:
                return np.nan
            a, _ = s.split("-", 1)
            try:
                h0 = int(a.strip())
                # 0â€“23 aralÄ±ÄŸÄ±na zorla
                h0 = max(0, min(23, h0))
                return h0
            except Exception:
                return np.nan

        df["hour"] = df[c_hrange].map(parse_start_hour).astype("Int64")

    # Ä°steÄŸe baÄŸlÄ±: hour_range stringini de sakla (ileride lazÄ±m olursa)
    if c_hrange:
        df["hour_range_3h"] = df[c_hrange].astype(str)

    # GeÃ§ersiz satÄ±rlarÄ± at
    df = df.dropna(subset=["date", "hour", "geoid"]).copy()

    # Zaman damgasÄ±: tarih + saat
    df["timestamp"] = df["date"].dt.floor("D") + pd.to_timedelta(
        df["hour"].fillna(0).astype(int),
        unit="h",
    )

    return df

def normalize_daily_schema(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    cols = {c.lower(): c for c in df.columns}

    def pick(*names):
        for n in names:
            if n in df.columns:
                return n
            if n.lower() in cols:
                return cols[n.lower()]
        return None

    c_date  = pick("date")
    c_geoid = pick("geoid", "GEOID", "cell_id", "id")
    c_risk  = pick("risk_score", "p_stack", "prob", "probability", "score", "risk")

    if not (c_date and c_geoid and c_risk):
        raise ValueError("GÃ¼nlÃ¼k veri iÃ§in 'date, geoid, risk_score' zorunlu.")

    df["date"] = pd.to_datetime(df[c_date], errors="coerce").dt.floor("D")
    df["geoid"] = df[c_geoid].astype(str)
    df["risk_score"] = pd.to_numeric(df[c_risk], errors="coerce")

    df = df.dropna(subset=["date", "geoid"]).copy()
    return df

def rgba_to_hex(rgba):
    """[r,g,b,a] â†’ '#rrggbb'"""
    try:
        r, g, b, _ = rgba
        return "#{:02x}{:02x}{:02x}".format(int(r), int(g), int(b))
    except Exception:
        return "#dddddd"
        
# ------------------------------------------------------------
# ğŸ§© GEOID normalizasyonu (harita iÃ§in 11 haneli + ÅŸehir geneli = '0')
# ------------------------------------------------------------
def normalize_geoid_for_map(df: pd.DataFrame) -> pd.DataFrame:
    """
    - 'geoid' kolonu varsa:
      * GEOID=0 â†’ '0' olarak kalÄ±r (ÅŸehir geneli)
      * DiÄŸer tÃ¼m deÄŸerler â†’ sayÄ±ya Ã§evrilip 11 haneli zero-pad yapÄ±lÄ±r
        (Ã¶rn. 6075010101 â†’ '06075010101')
    """
    df = df.copy()
    if "geoid" not in df.columns:
        return df

    # Ã–nce hepsini string yap
    df["geoid"] = df["geoid"].astype(str)

    # Åehir geneli satÄ±rlar
    mask_city = df["geoid"].isin(["0", "0.0"])

    # HÃ¼cre satÄ±rlarÄ±
    mask_cells = ~mask_city

    if mask_cells.any():
        df.loc[mask_cells, "geoid"] = (
            pd.to_numeric(df.loc[mask_cells, "geoid"], errors="coerce")
              .astype("Int64")
              .astype(str)
              .str.zfill(11)
        )

    # Åehir geneli satÄ±rlarÄ± tek tip olsun
    if mask_city.any():
        df.loc[mask_city, "geoid"] = "0"

    return df
    
# ------------------------------------------------------------
# ğŸ—ºï¸ GeoJSON yÃ¼kleyici & Ã¶zellik zenginleÅŸtirme
# ------------------------------------------------------------
@st.cache_data(show_spinner=False)
def load_geojson() -> dict:
    """
    Yerel sf_cells.geojson dosyasÄ±nÄ± okur.
    2_ğŸ—ºï¸_Risk_HaritasÄ±.py ile aynÄ± mantÄ±k.
    """
    if os.path.exists(GEOJSON_LOCAL):
        with open(GEOJSON_LOCAL, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def _digits11(x) -> str:
    """
    GeoJSON properties iÃ§indeki GEOID adayÄ±nÄ± 11 haneye zorlar.
    """
    s = "".join(ch for ch in str(x) if ch.isdigit())
    return s.zfill(11) if s else ""

def enrich_geojson_with_risk(gj: dict, agg_df: pd.DataFrame) -> dict:
    """
    sf_cells.geojson iÃ§indeki her hÃ¼creye:
      - risk_mean
      - risk_bucket
      - expected_count (varsa)
      - top1_category (varsa)
    gibi Ã¶zet bilgileri yazar ve fill_color atar.
    """
    if not gj or agg_df is None or agg_df.empty:
        return gj

    agg_df = agg_df.copy()
    # GEOID'ler zaten normalize_geoid_for_map ile gelmiÅŸ olmalÄ±
    agg_df["geoid"] = agg_df["geoid"].astype(str)
    risk_map = agg_df.set_index("geoid")

    feats_out = []
    for feat in gj.get("features", []):
        props = dict(feat.get("properties") or {})

        # GeoJSON iÃ§inden GEOID adayÄ± bul
        raw = None
        for k in ("geoid", "GEOID", "cell_id", "id", "geoid11", "geoid_11"):
            if k in props:
                raw = props[k]
                break
        if raw is None:
            for k, v in props.items():
                if "geoid" in str(k).lower():
                    raw = v
                    break

        key = _digits11(raw)
        props["display_id"] = str(raw) if raw not in (None, "") else key
        props["geoid_norm"] = key

        # VarsayÄ±lan boÅŸ deÄŸerler
        props.setdefault("risk_mean_txt", "")
        props.setdefault("risk_bucket", "")
        props.setdefault("expected_count_txt", "")
        props.setdefault("top1_category", "")
        props.setdefault("fill_color", [220, 220, 220, 160])  # Ã‡ok dÃ¼ÅŸÃ¼k default

        if key and key in risk_map.index:
            row = risk_map.loc[key]

            # Risk bucket ve renk
            bucket = row.get("risk_bucket", "")
            if not bucket and "risk_mean" in row:
                bucket = bucket_of(row["risk_mean"])
            props["risk_bucket"] = str(bucket)

            color = COLOR_MAP.get(bucket, [220, 220, 220, 160])
            props["fill_color"] = color

            # Ortalama risk
            try:
                r = float(row.get("risk_mean", np.nan))
                if r == r:
                    props["risk_mean_txt"] = f"{min(max(r, 0.0), 0.999):.3f}"
            except Exception:
                pass

            # Beklenen suÃ§ (gÃ¼n/saat baÅŸÄ±)
            def f3(x):
                try:
                    return f"{float(x):.3f}"
                except Exception:
                    return ""

            if "expected_crimes" in row.index:
                props["expected_count_txt"] = f3(row["expected_crimes"])
            elif "expected_count" in row.index:
                props["expected_count_txt"] = f3(row["expected_count"])

            # En olasÄ± suÃ§ tÃ¼rÃ¼
            if "top1_category" in row.index:
                props["top1_category"] = str(row["top1_category"] or "")

        feats_out.append({**feat, "properties": props})

    return {**gj, "features": feats_out}

# ------------------------------------------------------------
# ğŸ§® Risk bucket (sabit eÅŸikler)
# ------------------------------------------------------------
RISK_BUCKETS = [
    (0.00, 0.20, "Ã‡ok DÃ¼ÅŸÃ¼k", [220, 220, 220, 160]),
    (0.20, 0.40, "DÃ¼ÅŸÃ¼k",     [180, 210, 255, 200]),
    (0.40, 0.60, "Orta",      [255, 220, 130, 210]),
    (0.60, 0.80, "YÃ¼ksek",    [255, 170, 110, 220]),
    (0.80, 1.01, "Ã‡ok YÃ¼ksek",[255,  90,  90, 240]),
]

def bucket_of(v: float) -> str:
    x = 0.0 if pd.isna(v) else float(v)
    for lo, hi, name, _ in RISK_BUCKETS:
        if lo <= x < hi:
            return name
    return "Ã‡ok DÃ¼ÅŸÃ¼k"

COLOR_MAP = {name: rgba for _, _, name, rgba in RISK_BUCKETS}

def csv_bytes(df: pd.DataFrame) -> bytes:
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    return buf.getvalue().encode("utf-8")

# ------------------------------------------------------------
# ğŸ›ï¸ UI â€” Ayarlar
# ------------------------------------------------------------
st.set_page_config(page_title="ğŸŒ€ SuÃ§ Tahmini", layout="wide")
st.sidebar.header("âš™ï¸ Ayarlar")

# Zaman modu
mode = st.sidebar.radio(
    "Zaman Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼",
    ["3 Saatlik Bloklar (â‰¤7 gÃ¼n)", "GÃ¼nlÃ¼k (â‰¤365 gÃ¼n)"],
    index=0,
)

# Saatlik modda SADECE saat aralÄ±ÄŸÄ± seÃ§imi
def default_hour_block_label(hour_blocks: dict) -> str:
    """
    San Francisco yerel saatine gÃ¶re ÅŸu an hangi blok iÃ§indeysek
    o blok etiketini dÃ¶ndÃ¼rÃ¼r. Hata olursa '18â€“21' fallback.
    """
    fallback = "18â€“21"
    try:
        if ZoneInfo is None:
            raise RuntimeError("ZoneInfo yok")
        now_sf = datetime.now(ZoneInfo("America/Los_Angeles"))
        h = now_sf.hour  # 0â€“23
        for label, (h0, h1) in hour_blocks.items():
            if h0 <= h <= h1:
                return label
        return fallback
    except Exception:
        return fallback

if mode.startswith("3 Saatlik"):
    st.sidebar.subheader("Saat AralÄ±ÄŸÄ±")

    # 3 saatlik bloklar
    hour_blocks = {
        "00â€“03": (0, 2),
        "03â€“06": (3, 5),
        "06â€“09": (6, 8),
        "09â€“12": (9, 11),
        "12â€“15": (12, 14),
        "15â€“18": (15, 17),
        "18â€“21": (18, 20),
        "21â€“24": (21, 23),
    }

    default_label = default_hour_block_label(hour_blocks)

    selected_label = st.sidebar.select_slider(
        "Saat aralÄ±ÄŸÄ±",
        options=list(hour_blocks.keys()),
        value=default_label,
    )

    h0, h1 = hour_blocks[selected_label]
    selected_hours = list(range(h0, h1 + 1))
else:
    selected_hours = []

# Tarih aralÄ±ÄŸÄ±  âœ SF yerel zamanÄ±na gÃ¶re
if ZoneInfo is not None:
    now_sf = datetime.now(ZoneInfo("America/Los_Angeles"))
else:
    # Fallback: UTC / sistem zamanÄ±
    now_sf = datetime.utcnow()

max_days = 7 if mode.startswith("3 Saatlik") else 365
st.sidebar.caption(
    f"{'3 Saatlik' if max_days == 7 else 'GÃ¼nlÃ¼k'} gÃ¶rÃ¼nÃ¼mde en fazla {max_days} gÃ¼n seÃ§ebilirsiniz. "
    "(San Francisco yerel zamanÄ± baz alÄ±nÄ±r.)"
)

# ğŸ” MOD: Saatlik ve GÃ¼nlÃ¼k mod iÃ§in farklÄ± varsayÄ±lan tarih aralÄ±ÄŸÄ±
if mode.startswith("3 Saatlik"):
    # 3 Saatlik gÃ¶rÃ¼nÃ¼m: SF bugÃ¼n (sadece bugÃ¼nÃ¼n bloklarÄ±)
    d_start_default = now_sf.date()
    d_end_default   = now_sf.date()
else:
    # GÃ¼nlÃ¼k (365 gÃ¼n) gÃ¶rÃ¼nÃ¼m: SF bugÃ¼n
    d_start_default = now_sf.date()
    d_end_default   = now_sf.date()

d_start = st.sidebar.date_input("BaÅŸlangÄ±Ã§ tarihi", value=d_start_default)
d_end   = st.sidebar.date_input("BitiÅŸ tarihi",     value=d_end_default)

if (pd.to_datetime(d_end) - pd.to_datetime(d_start)).days > max_days:
    d_end = (pd.to_datetime(d_start) + pd.Timedelta(days=max_days)).date()
    st.sidebar.warning(f"SeÃ§im {max_days} gÃ¼nÃ¼ aÅŸamaz; bitiÅŸ {d_end} olarak gÃ¼ncellendi.")


# GEOID filtre
geof_txt = st.sidebar.text_input("GEOID filtre (virgÃ¼lle ayÄ±r)", value="")
geoids_sel = [g.strip() for g in geof_txt.split(",") if g.strip()]

# Top-K (tablo)
top_k = st.sidebar.slider("Top-K (tablo)", 10, 200, 50, step=10)

# ------------------------------------------------------------
# ğŸ“¥ Veri yÃ¼kleme ve filtre
# ------------------------------------------------------------
@st.cache_data(show_spinner=False)
def load_hourly_dataframe() -> pd.DataFrame:
    """
    3-saatlik blok veri kaynaÄŸÄ±:
      1) EÄŸer mevcutsa: data/crime_forecast_7days_all_geoids_FRstyle.csv
      2) DeÄŸilse: artifact iÃ§indeki risk_3h_next7d_top3
    """
    # Ã–nce yerel CSV'yi dene
    if os.path.exists(CSV_HOURLY_FRSTYLE):
        st.sidebar.success("3-saatlik veri kaynaÄŸÄ±: ğŸ”¹ Yerel CSV (FRstyle)")
        raw = pd.read_csv(CSV_HOURLY_FRSTYLE)
        return normalize_hourly_schema(raw)

    # CSV yoksa eski davranÄ±ÅŸ: artifact'ten oku
    st.sidebar.warning("3-saatlik veri kaynaÄŸÄ±: ğŸª£ GitHub artifact (risk_3h_next7d_top3)")
    raw = load_artifact_member(ARTIFACT_MEMBER_HOURLY)
    return normalize_hourly_schema(raw)

@st.cache_data(show_spinner=False)
def load_daily_dataframe() -> pd.DataFrame:
    raw = load_artifact_member(ARTIFACT_MEMBER_DAILY)
    return normalize_daily_schema(raw)

agg = pd.DataFrame()
view_df = pd.DataFrame()
view_df_city = pd.DataFrame()   # geoid == "0" (ÅŸehir geneli)
view_df_cells = pd.DataFrame()  # geoid != "0" (hÃ¼creler)
time_col = "timestamp"

with st.spinner("Veriler yÃ¼kleniyorâ€¦"):
    if mode.startswith("3 Saatlik"):
        src = load_hourly_dataframe()
        # ğŸ” GEOID formatÄ±nÄ± harita iÃ§in normalize et
        src = normalize_geoid_for_map(src)

        t0 = pd.to_datetime(d_start)
        t1 = pd.to_datetime(d_end) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
        df = src[(src["timestamp"] >= t0) & (src["timestamp"] <= t1)].copy()
        if geoids_sel:
            df = df[df["geoid"].isin(geoids_sel)].copy()
        if selected_hours:
            df = df[df["hour"].isin(selected_hours)].copy()

        # EÄŸer bu pencere iÃ§in hiÃ§ kayÄ±t yoksa â†’ tÃ¼m saatlik risk Ã§Ä±ktÄ±sÄ±nÄ± kullan
        if df.empty:
            st.info(
                "SeÃ§ilen tarih/saat aralÄ±ÄŸÄ± iÃ§in kayÄ±t bulunamadÄ±; "
                "en gÃ¼ncel saatlik risk Ã§Ä±ktÄ±sÄ± gÃ¶steriliyor."
            )
            df = src.copy()

        view_df = df
        time_col = "timestamp"

    else:
        src = load_daily_dataframe()
        # ğŸ” GEOID formatÄ±nÄ± harita iÃ§in normalize et
        src = normalize_geoid_for_map(src)

        t0 = pd.to_datetime(d_start).floor("D")
        t1 = pd.to_datetime(d_end).floor("D")
        df = src[(src["date"] >= t0) & (src["date"] <= t1)].copy()
        if geoids_sel:
            df = df[df["geoid"].isin(geoids_sel)].copy()

        # EÄŸer bu pencere iÃ§in hiÃ§ kayÄ±t yoksa â†’ tÃ¼m gÃ¼nlÃ¼k risk Ã§Ä±ktÄ±sÄ±nÄ± kullan
        if df.empty:
            st.info(
                "SeÃ§ilen tarih aralÄ±ÄŸÄ± iÃ§in kayÄ±t bulunamadÄ±; "
                "en gÃ¼ncel gÃ¼nlÃ¼k risk Ã§Ä±ktÄ±sÄ± gÃ¶steriliyor."
            )
            df = src.copy()

        view_df = df
        time_col = "date"
        
    if len(view_df):
        # GEOID=0 â†’ ÅŸehir geneli, diÄŸerleri hÃ¼creler
        mask_city = view_df["geoid"].astype(str) == "0"
        view_df_city = view_df[mask_city].copy()
        view_df_cells = view_df[~mask_city].copy()

        if len(view_df_cells):
            # Harita iÃ§in GEOID bazlÄ± risk ortalamasÄ± (sadece hÃ¼creler)
            # 1) Ã–nce risk_prob'u dene
            metric_col = None
            use_prob = False

            if "risk_prob" in view_df_cells.columns:
                max_prob = pd.to_numeric(
                    view_df_cells["risk_prob"], errors="coerce"
                ).max()
                if pd.notna(max_prob) and max_prob > 0:
                    metric_col = "risk_prob"
                    use_prob = True

            # 2) EÄŸer risk_prob yoksa veya hep 0'sa risk_score'a dÃ¶n
            if metric_col is None and "risk_score" in view_df_cells.columns:
                metric_col = "risk_score"
                use_prob = False

            if metric_col is None:
                agg = pd.DataFrame()
            else:
                tmp = view_df_cells.copy()
                tmp[metric_col] = pd.to_numeric(tmp[metric_col], errors="coerce")

                grp = tmp.groupby("geoid", as_index=False)[metric_col].mean()

                if use_prob:
                    grp = grp.rename(columns={metric_col: "risk_mean"})
                else:
                    # risk_score bÃ¼yÃ¼k ihtimalle yÃ¼zde â†’ 0â€“100'Ã¼ 0â€“1'e Ã§evir
                    max_val = grp[metric_col].max()
                    if pd.notna(max_val) and max_val > 1.0:
                        grp["risk_mean"] = grp[metric_col].clip(0, 100) / 100.0
                    else:
                        grp["risk_mean"] = grp[metric_col].clip(0.0, 1.0)

                agg = grp[["geoid", "risk_mean"]].copy()
                # GEOID'leri string olarak tut (GeoJSON'daki ile bire bir eÅŸleÅŸsin)
                agg["geoid"] = agg["geoid"].astype(str)
        else:
            view_df_cells = pd.DataFrame()
            agg = pd.DataFrame()

        # Opsiyonel kolonlarÄ± GEOID bazÄ±nda Ã¶zetle (risk_prob, expected_crimes, top1_category vs.)
        def safe_mean(col_name: str):
            if len(view_df_cells) and col_name in view_df_cells.columns:
                out = view_df_cells.groupby("geoid", as_index=False)[col_name].mean()
                out["geoid"] = out["geoid"].astype(str)
                return out
            return None

        def safe_first(col_name: str):
            if len(view_df_cells) and col_name in view_df_cells.columns:
                tmp = (
                    view_df_cells.sort_values(time_col)
                    .groupby("geoid", as_index=False)[col_name]
                    .first()
                )
                tmp["geoid"] = tmp["geoid"].astype(str)
                return tmp
            return None

        if len(agg):
            for c in ["risk_prob", "expected_crimes", "expected_count"]:
                tmp = safe_mean(c)
                if tmp is not None and len(tmp):
                    agg = agg.merge(tmp, on="geoid", how="left")

            for c in ["risk_level", "risk_decile", "top1_category"]:
                tmp = safe_first(c)
                if tmp is not None and len(tmp):
                    agg = agg.merge(tmp, on="geoid", how="left")

# ------------------------------------------------------------
# ğŸ” DEBUG â€” Artifact ZIP iÃ§indeki dosya isimlerini gÃ¶ster
# ------------------------------------------------------------
with st.expander("ğŸ” Artifact iÃ§indeki dosya isimleri (debug)", expanded=False):
    try:
        url, headers = resolve_latest_artifact_zip_url(
            REPOSITORY_OWNER, REPOSITORY_NAME, ARTIFACT_NAME_SHOULD_CONTAIN
        )
        if url:
            r = requests.get(url, headers=headers, timeout=60)
            r.raise_for_status()
            with zipfile.ZipFile(BytesIO(r.content)) as outer:
                names_outer = outer.namelist()
            st.write(f"DÄ±ÅŸ ZIP toplam dosya: {len(names_outer)}")
            st.write(names_outer)

            with zipfile.ZipFile(BytesIO(r.content)) as outer2:
                for name in outer2.namelist():
                    if name.lower().endswith(".zip"):
                        with outer2.open(name) as f_z:
                            inner_bytes = f_z.read()
                        try:
                            with zipfile.ZipFile(BytesIO(inner_bytes)) as inner:
                                st.write(f"Ä°Ã§ ZIP: {name}")
                                st.write(inner.namelist())
                        except zipfile.BadZipFile:
                            st.write(f"Ä°Ã§ ZIP aÃ§Ä±lamadÄ±: {name}")
        else:
            st.warning("Artifact bulunamadÄ± veya token eksik.")
    except Exception as e:
        st.error(f"Debug sÄ±rasÄ±nda hata: {e}")

# ------------------------------------------------------------
# ğŸ—ºï¸ HARÄ°TA â€” EN ÃœSTE (Folium + tÄ±klama ile GEOID seÃ§imi)
# ------------------------------------------------------------
if len(agg):
    agg["risk_bucket"] = agg["risk_mean"].map(bucket_of)
    agg_sorted = agg.sort_values("risk_mean", ascending=False).reset_index(drop=True)
else:
    agg_sorted = agg

st.subheader("ğŸ—ºï¸ Harita â€” 5 seviye risk renklendirme")

geojson = load_geojson()

clicked_geoid = None  # haritada tÄ±klanan GEOID

if not len(agg_sorted):
    if len(view_df_city):
        st.info(
            "Bu aralÄ±kta sadece ÅŸehir geneli (GEOID=0) iÃ§in risk Ã¼retilmiÅŸ; "
            "hÃ¼cre (GEOID) bazlÄ± risk olmadÄ±ÄŸÄ± iÃ§in harita devre dÄ±ÅŸÄ±."
        )
    else:
        st.info("SeÃ§ilen aralÄ±kta GEOID bazlÄ± risk verisi bulunamadÄ±.")
elif not geojson:
    st.info("GeoJSON (sf_cells.geojson) bulunamadÄ±; harita devre dÄ±ÅŸÄ±.")
else:
    gj_enriched = enrich_geojson_with_risk(geojson, agg_sorted)

    st.markdown(
        "**Lejand:** "
        "<span style='background:#ddd;padding:2px 6px;border-radius:4px;'>Ã‡ok DÃ¼ÅŸÃ¼k</span> "
        "<span style='background:#b4d2ff;padding:2px 6px;border-radius:4px;'>DÃ¼ÅŸÃ¼k</span> "
        "<span style='background:#ffdc82;padding:2px 6px;border-radius:4px;'>Orta</span> "
        "<span style='background:#ffaa6e;padding:2px 6px;border-radius:4px;'>YÃ¼ksek</span> "
        "<span style='background:#ff5a5a;padding:2px 6px;border-radius:4px;'>Ã‡ok YÃ¼ksek</span> ",
        unsafe_allow_html=True,
    )

    # --- Folium haritasÄ±
    m = folium.Map(
        location=[37.7749, -122.4194],
        zoom_start=11,
        tiles="cartodbpositron",
        control_scale=True,
    )

    def style_fn(feature):
        props = feature.get("properties", {})
        rgba = props.get("fill_color", [220, 220, 220, 160])
        return {
            "fillColor": rgba_to_hex(rgba),
            "color": "#505050",
            "weight": 0.5,
            "fillOpacity": float(rgba[3]) / 255.0 if len(rgba) == 4 else 0.6,
        }

    def highlight_fn(feature):
        return {"weight": 2, "color": "#000000"}
    
    tooltip = folium.GeoJsonTooltip(
        fields=["display_id", "risk_bucket", "risk_mean_txt", "expected_count_txt", "top1_category"],
        aliases=[
            "GEOID:",
            "Risk seviyesi:",
            "Ortalama risk skoru (0â€“1):",
            "Beklenen toplam olay:",
            "En olasÄ± suÃ§ tÃ¼rÃ¼:",
        ],
        sticky=True,
    )

    folium.GeoJson(
        gj_enriched,
        name="Risk",
        style_function=style_fn,
        highlight_function=highlight_fn,
        tooltip=tooltip,
    ).add_to(m)

    # Streamlit iÃ§inde haritayÄ± render et ve tÄ±klanan feature'Ä± yakala
    folium_ret = st_folium(
        m,
        width=None,
        height=520,
        returned_objects=["last_active_drawing"],
        key="sutam_fr_map",
    )

    if folium_ret and folium_ret.get("last_active_drawing"):
        props = folium_ret["last_active_drawing"].get("properties", {}) or {}
        clicked_geoid = str(
            props.get("geoid_norm")   # ğŸ‘ˆ Ã–NCE normalize edilmiÅŸ olan
            or props.get("display_id")
            or props.get("geoid")
            or props.get("GEOID")
            or ""
        ).strip()

        # tÄ±klanan GEOID'i session_state'e yaz (diÄŸer bileÅŸenler kullanacak)
        if clicked_geoid:
            st.session_state["clicked_geoid_fr"] = clicked_geoid

# ------------------------------------------------------------
# ğŸ§  Ã–zet kartlar
# ------------------------------------------------------------
st.title("ğŸŒ€ SuÃ§ Tahmini â€” HaritalÄ± GEOID gÃ¶rÃ¼nÃ¼m")
st.caption(
    "3-saatlik bloklar (â‰¤7 gÃ¼n) veya gÃ¼nlÃ¼k (â‰¤365 gÃ¼n) pencerede GEOID bazlÄ± ortalama risk."
)

c1, c2, c3 = st.columns(3)
c1.metric("Kapsanan kayÄ±t", f"{len(view_df):,}")
c2.metric(
    "GEOID sayÄ±sÄ±",
    f"{agg_sorted['geoid'].nunique():,}" if len(agg_sorted) else "0",
)
c3.metric(
    "Ortalama risk",
    f"{view_df['risk_score'].mean():.3f}" if len(view_df) else "â€”",
)

# GEOID etiketleyici (0 iÃ§in Ã¶zel label)
def geoid_label(g: str) -> str:
    return "Åehir geneli (GEOID=0)" if str(g) == "0" else str(g)

# GEOID seÃ§imi (detay sekmeleri iÃ§in)
options = []
# Ã–nce ÅŸehir geneli (varsa)
if len(view_df_city):
    options.append("0")
# Sonra hÃ¼creler (harita/Top-K ile tutarlÄ±)
if len(view_df_cells):
    options.extend(sorted(view_df_cells["geoid"].astype(str).unique().tolist()))

if options:
    # 1) Haritada tÄ±klanan GEOID varsa onu al
    clicked_geoid = st.session_state.get("clicked_geoid_fr", clicked_geoid)

    # 2) GeÃ§erli bir seÃ§enek deÄŸilse 0. index
    default_index = 0
    if clicked_geoid and clicked_geoid in options:
        default_index = options.index(clicked_geoid)

    selected_geoid = st.selectbox(
        "Detay gÃ¶stermek iÃ§in GEOID seÃ§:",
        options=options,
        index=default_index,
        format_func=geoid_label,
    )
else:
    selected_geoid = None
    
# Top-K her halÃ¼kÃ¢rda hesaplayalÄ±m (sadece hÃ¼creler Ã¼zerinden)
topk = agg_sorted.head(top_k).copy() if len(agg_sorted) else pd.DataFrame()

# ------------------------------------------------------------
# ğŸ” Debug: SeÃ§ili GEOID iÃ§in ham kayÄ±tlar
# ------------------------------------------------------------
with st.expander("ğŸ” Debug: SeÃ§ili GEOID ham kayÄ±tlar"):
    if selected_geoid is not None and len(view_df):
        df_dbg = (
            view_df[view_df["geoid"] == selected_geoid]
            [[time_col, "geoid", "risk_score"] + (
                ["risk_prob"] if "risk_prob" in view_df.columns else []
            )]
            .sort_values(time_col)
            .tail(10)
        )
        st.write(df_dbg)

        if "risk_prob" in view_df.columns:
            st.write(
                "risk_prob min/max:",
                float(pd.to_numeric(view_df["risk_prob"], errors="coerce").min()),
                float(pd.to_numeric(view_df["risk_prob"], errors="coerce").max()),
            )

# ------------------------------------------------------------
# ğŸ” Sekmeli gÃ¶rÃ¼nÃ¼m: Ã–zet & nedenler / Zaman serisi / IsÄ± haritasÄ± & Top-K
# ------------------------------------------------------------
tab1, tab2, tab3 = st.tabs(["Ã–zet & Nedenler", "Zaman Serisi", "IsÄ± HaritasÄ± / Top-K"])

# --------------------------- TAB 1: Ã–zet & Nedenler ---------------------------
with tab1:
    st.subheader("ğŸ“Œ SeÃ§ili GEOID iÃ§in risk Ã¶zeti ve nedenler")

    if selected_geoid is None or len(view_df) == 0:
        st.info("GÃ¶rÃ¼ntÃ¼lenecek veri bulunamadÄ±.")
    else:
        df_sel = (
            view_df[view_df["geoid"] == selected_geoid]
            .sort_values(time_col)
            .copy()
        )
        if len(df_sel) == 0:
            st.info("SeÃ§ili GEOID iÃ§in veri yok.")
        else:
            # ğŸ” MOD: GÃ¼nlÃ¼k (365 gÃ¼n) modunda mÃ¼mkÃ¼nse "bugÃ¼n" satÄ±rÄ±nÄ± kullan
            if time_col == "date":
                today_dt = pd.to_datetime(datetime.now().date())
                mask_today = df_sel[time_col] == today_dt
                if mask_today.any():
                    latest = df_sel[mask_today].iloc[0]
                else:
                    # BugÃ¼n yoksa, eski davranÄ±ÅŸ: en son satÄ±r
                    latest = df_sel.iloc[-1]
            else:
                # 3-saatlik modda olduÄŸu gibi son satÄ±rÄ± kullan
                latest = df_sel.iloc[-1]
        
            def gv(col, default="â€”"):
                return latest[col] if col in df_sel.columns and pd.notna(latest[col]) else default

            # Ãœstte kÃ¼Ã§Ã¼k metrik kartlar
            c1, c2, c3 = st.columns(3)
            c1.metric("GEOID", selected_geoid)
            c2.metric("Son pencere risk skoru", f"{gv('risk_score', np.nan):.4f}" if gv("risk_score", np.nan) == gv("risk_score", np.nan) else "â€”")
            if "risk_prob" in df_sel.columns:
                c3.metric("Risk olasÄ±lÄ±ÄŸÄ±", f"{gv('risk_prob', np.nan):.4f}" if gv("risk_prob", np.nan) == gv("risk_prob", np.nan) else "â€”")
            elif "risk_mean" in agg_sorted.columns:
                c3.metric("Ortalama risk", f"{float(agg_sorted.loc[agg_sorted['geoid']==selected_geoid, 'risk_mean'].iloc[0]):.4f}")
            else:
                c3.metric("Ortalama risk", "â€”")

            # Ä°kinci satÄ±r: beklenen suÃ§, komÅŸu suÃ§, 911/311
            c4, c5, c6 = st.columns(3)
            if "expected_crimes" in df_sel.columns:
                c4.metric("Beklenen suÃ§ (son pencere)", f"{gv('expected_crimes', np.nan):.4f}" if gv("expected_crimes", np.nan) == gv("expected_crimes", np.nan) else "â€”")
            elif "expected_count" in df_sel.columns:
                c4.metric("Beklenen suÃ§ (son pencere)", f"{gv('expected_count', np.nan):.4f}" if gv("expected_count", np.nan) == gv("expected_count", np.nan) else "â€”")
            else:
                c4.metric("Beklenen suÃ§", "â€”")

            if "neighbor_crime_7d" in df_sel.columns:
                c5.metric("KomÅŸu suÃ§ (7gÃ¼n)", f"{gv('neighbor_crime_7d', 0):.1f}")
            elif "neighbor_crime_24h" in df_sel.columns:
                c5.metric("KomÅŸu suÃ§ (24s)", f"{gv('neighbor_crime_24h', 0):.1f}")
            else:
                c5.metric("KomÅŸu suÃ§", "â€”")

            if "911_request_count_hour_range" in df_sel.columns:
                c6.metric("911 Ã§aÄŸrÄ±larÄ± (saat aralÄ±ÄŸÄ±)", f"{gv('911_request_count_hour_range', 0):.1f}")
            elif "911_geo_last3d" in df_sel.columns:
                c6.metric("911 Ã§aÄŸrÄ±larÄ± (3gÃ¼n)", f"{gv('911_geo_last3d', 0):.1f}")
            else:
                c6.metric("911 Ã§aÄŸrÄ±larÄ±", "â€”")

            # POI / ulaÅŸÄ±m / demografi
            c7, c8, c9 = st.columns(3)
            if "poi_risk_score" in df_sel.columns:
                c7.metric("POI risk skoru", f"{gv('poi_risk_score', 0):.2f}")
            elif "poi_total_count" in df_sel.columns:
                c7.metric("POI sayÄ±sÄ±", f"{gv('poi_total_count', 0):.0f}")
            else:
                c7.metric("POI", "â€”")

            if "bus_stop_count" in df_sel.columns:
                c8.metric("OtobÃ¼s duraÄŸÄ± sayÄ±sÄ±", f"{gv('bus_stop_count', 0):.0f}")
            elif "train_stop_count" in df_sel.columns:
                c8.metric("Tren duraÄŸÄ± sayÄ±sÄ±", f"{gv('train_stop_count', 0):.0f}")
            else:
                c8.metric("Toplu taÅŸÄ±ma", "â€”")

            if "population" in df_sel.columns:
                c9.metric("NÃ¼fus", f"{gv('population', 0):,.0f}")
            else:
                c9.metric("NÃ¼fus", "â€”")

            # Hava durumu / zaman bayraklarÄ± mini satÄ±r
            flags = []
            if "wx_tavg" in df_sel.columns:
                flags.append(f"Ortalama sÄ±caklÄ±k: {gv('wx_tavg', 'â€”')}")
            if "wx_prcp" in df_sel.columns:
                flags.append(f"YaÄŸÄ±ÅŸ (mm): {gv('wx_prcp', 'â€”')}")
            if "wx_is_rainy" in df_sel.columns:
                if gv("wx_is_rainy", 0) == 1:
                    flags.append("YaÄŸÄ±ÅŸlÄ± gÃ¼n")
            if "wx_is_hot_day" in df_sel.columns:
                if gv("wx_is_hot_day", 0) == 1:
                    flags.append("SÄ±cak gÃ¼n")

            if "is_night" in df_sel.columns:
                flags.append("Gece" if gv("is_night", 0) == 1 else "GÃ¼ndÃ¼z")
            if "is_weekend" in df_sel.columns:
                flags.append("Hafta sonu" if gv("is_weekend", 0) == 1 else "Hafta iÃ§i")
            if "is_holiday" in df_sel.columns:
                if gv("is_holiday", 0) == 1:
                    flags.append("ResmÃ® tatil")
            if "is_business_hour" in df_sel.columns:
                if gv("is_business_hour", 0) == 1:
                    flags.append("Mesai saatleri")
            if "is_school_hour" in df_sel.columns:
                if gv("is_school_hour", 0) == 1:
                    flags.append("Okul saatleri")

            # Sezon / gÃ¼n / saat aralÄ±ÄŸÄ± ek bilgi
            if "season_x" in df_sel.columns:
                flags.append(f"Mevsim: {gv('season_x', 'â€”')}")
            if "day_of_week_x" in df_sel.columns:
                flags.append(f"GÃ¼n: {gv('day_of_week_x', 'â€”')}")
            if "hour_range_x" in df_sel.columns:
                flags.append(f"Saat aralÄ±ÄŸÄ±: {gv('hour_range_x', 'â€”')}")

            if len(flags):
                st.markdown(
                    "<br>".join([f"â€¢ {f}" for f in flags]),
                    unsafe_allow_html=True,
                )

            st.markdown("---")

            # ----------------- NEDENLER / AÃ‡IKLAMA BLOÄU -----------------
            st.markdown("### ğŸ§  Modelin Ã¶ne Ã§Ä±kardÄ±ÄŸÄ± nedenler")

            reasons = []
            for i in range(1, 6):
                col = f"reason_{i}"
                if col in df_sel.columns:
                    txt = gv(col, "")
                    if isinstance(txt, str) and txt.strip():
                        reasons.append(txt.strip())

            col_left, col_right = st.columns([1, 1])

            with col_left:
                if reasons:
                    st.markdown("**Ana nedenler (otomatik aÃ§Ä±klamalar):**")
                    for r in reasons:
                        st.markdown(f"- {r}")
                else:
                    st.info("Bu GEOID iÃ§in kayÄ±tlÄ± ayrÄ±ntÄ±lÄ± 'reason_1â€“5' aÃ§Ä±klamasÄ± bulunamadÄ±.")

            with col_right:
                if "explanation_report" in df_sel.columns:
                    rep = gv("explanation_report", "")
                    if isinstance(rep, str) and rep.strip():
                        st.markdown("**DetaylÄ± aÃ§Ä±klama raporu:**")
                        st.markdown(
                            f"<div style='max-height:260px; overflow:auto; padding:6px; "
                            f"border-radius:6px; border:1px solid #ddd; background-color:#fafafa;'>"
                            f"{rep}</div>",
                            unsafe_allow_html=True,
                        )
                    else:
                        st.caption("DetaylÄ± aÃ§Ä±klama raporu boÅŸ.")
                else:
                    st.caption("`explanation_report` alanÄ± bu dataset iÃ§inde yok.")

            st.markdown("---")

            # ----------------- SUÃ‡ TÃœRÃœ KOMPOZÄ°SYONU TABLOSU -----------------
            st.markdown("### ğŸ§¬ Beklenen suÃ§ tÃ¼rÃ¼ kompozisyonu")

            # Top1â€“Top5 ve pay/olasÄ±lÄ±k/expected sÃ¼tunlarÄ±nÄ± derle
            rows = []
            for k in range(1, 5+1):
                cat_col = f"top{k}_category"
                share_col = f"top{k}_share"
                prob_col = f"top{k}_prob"
                exp_col = f"top{k}_expected"

                if cat_col not in df_sel.columns:
                    continue

                cat = gv(cat_col, "")
                if not isinstance(cat, str) or not cat.strip():
                    continue

                row = {"SÄ±ra": k, "SuÃ§ tÃ¼rÃ¼": cat}

                if share_col in df_sel.columns:
                    row["Pay (share)"] = gv(share_col, np.nan)
                if prob_col in df_sel.columns:
                    row["OlasÄ±lÄ±k (prob)"] = gv(prob_col, np.nan)
                if exp_col in df_sel.columns:
                    row["Beklenen sayÄ±"] = gv(exp_col, np.nan)

                rows.append(row)

            if rows:
                df_comp = pd.DataFrame(rows)
                st.dataframe(
                    df_comp.style.format(
                        {
                            "Pay (share)": "{:.3f}",
                            "OlasÄ±lÄ±k (prob)": "{:.3f}",
                            "Beklenen sayÄ±": "{:.3f}",
                        }
                    ),
                    use_container_width=True,
                )
            else:
                st.info("Top1â€“Top5 suÃ§ tÃ¼rÃ¼ kompozisyon bilgisi bu GEOID iÃ§in bulunamadÄ±.")

with tab2:
    st.subheader("ğŸ“ˆ Zaman serisi (risk_score)")

    if len(view_df) == 0:
        st.info("SeÃ§ilen tarih/saat aralÄ±ÄŸÄ± iÃ§in veri yok.")
    else:
        # VarsayÄ±lan: varsa Ã¶nce ÅŸehir geneli, sonra Top-K iÃ§indeki ilk 3 hÃ¼cre
        default_geoids = []
        if len(view_df_city):
            default_geoids.append("0")
        if len(topk):
            default_geoids.extend(topk["geoid"].head(3).tolist())

        # SeÃ§ilebilir GEOID listesi: ÅŸehir geneli + hÃ¼creler
        options_geoids = []
        if len(view_df_city):
            options_geoids.append("0")
        # HÃ¼creler (0 hariÃ§)
        options_geoids.extend(
            sorted([g for g in view_df["geoid"].astype(str).unique().tolist() if g != "0"])
        )

        chosen = st.multiselect(
            "Grafikte gÃ¶sterilecek GEOID'ler",
            options=options_geoids,
            default=default_geoids,
            format_func=geoid_label,
        )

        if len(chosen):
            piv = (
                view_df[view_df["geoid"].isin(chosen)]
                .pivot_table(
                    index=time_col,
                    columns="geoid",
                    values="risk_score",
                    aggfunc="mean",
                )
                .sort_index()
            )
            if len(piv):
                st.line_chart(piv, height=360)
            else:
                st.caption("SeÃ§ilen GEOID'ler iÃ§in veri yok.")
        else:
            st.caption("Grafik iÃ§in en az bir GEOID seÃ§in.")

# --------------------------- TAB 3: IsÄ± HaritasÄ± & Top-K ---------------------------
with tab3:
    st.subheader("ğŸ”¥ IsÄ± haritasÄ± (GEOID Ã— Zaman)")

    if len(view_df) == 0:
        st.info("SeÃ§ilen aralÄ±k iÃ§in veri yok.")
    else:
        heat_index = "hour" if mode.startswith("3 Saatlik") else "date"
        heat = (
            view_df.groupby([heat_index, "geoid"], as_index=False)["risk_score"]
            .mean()
            .pivot(index=heat_index, columns="geoid", values="risk_score")
            .sort_index()
        )

        # ğŸ”¥ IsÄ± haritasÄ± TÃœM GEOID'leri kapsar (ÅŸehir geneli = 0 dahil)
        st.dataframe(
            heat.style.format("{:.3f}"),
            use_container_width=True,
            height=420,
        )

        st.markdown("---")
        st.subheader("ğŸ” Top-K GEOID tablo & indir")

        if len(topk):
            st.dataframe(topk, use_container_width=True, height=320)
            st.download_button(
                "â¬‡ï¸ CSV indir (Top-K)",
                data=csv_bytes(topk),
                file_name="risk_topk.csv",
                mime="text/csv",
            )
        else:
            st.caption("Top-K tablosu iÃ§in yeterli veri yok.")

# ------------------------------------------------------------
# ğŸ§¾ Dipnot
# ------------------------------------------------------------
st.caption(
    "Kaynak: artifact 'fr-crime-outputs-parquet' â†’ "
    "risk_3h_next7d_top3 / risk_daily_next365d_top5 (parquet veya csv); "
    "veya yerel CSV: 'data/crime_forecast_7days_all_geoids_FRstyle.csv'. "
    "Harita geometri kaynaÄŸÄ±: repo iÃ§indeki 'data/sf_cells.geojson' dosyasÄ±."
)
