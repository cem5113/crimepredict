# pages/2_ðŸ—ºï¸_Risk_HaritasÄ±.py â€” ANLIK gÃ¶rÃ¼nÃ¼m (CSV: risk_hourly_grid_full_labeled.csv)

import io, os, json, zipfile
from typing import Optional, Iterable
from datetime import datetime
from zoneinfo import ZoneInfo

import pandas as pd
import streamlit as st
import pydeck as pdk
import requests

from components.last_update import show_last_update_badge
from components.meta import MODEL_VERSION, MODEL_LAST_TRAIN

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SAYFA BAÅžLIÄžI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ðŸ•’ AnlÄ±k SuÃ§ Risk HaritasÄ±")
st.caption(
    "Bu sayfa aÃ§Ä±ldÄ±ÄŸÄ± anda (SF yerel saatine gÃ¶re) geÃ§erli **hour_range** otomatik seÃ§ilir "
    "ve sadece o dilime ait riskler gÃ¶sterilir. Veriler doÄŸrudan CSVâ€™den okunur; "
    "**risk_level** yeniden hesaplanmaz."
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AYARLAR
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cfg = st.secrets if hasattr(st, "secrets") else {}
OWNER = cfg.get("artifact_owner", "cem5113")
REPO = cfg.get("artifact_repo", "crime_prediction_data")
ARTIFACT_NAME = cfg.get("artifact_name", "sf-crime-pipeline-output")  # Actions artifact adÄ±
CSV_TARGET_NAME = "risk_hourly_grid_full_labeled.csv"                  # Zip iÃ§indeki dosya
TARGET_TZ = cfg.get("risk_timezone", "America/Los_Angeles")            # AnlÄ±k saat TZ

# GeoJSON (Ã¶nce local â†’ artifact â†’ raw github)
GEOJSON_PATH_LOCAL_DEFAULT = cfg.get("geojson_path", "data/sf_cells.geojson")
RAW_GEOJSON_OWNER = cfg.get("geojson_owner", "cem5113")
RAW_GEOJSON_REPO  = cfg.get("geojson_repo",  "crimepredict")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GITHUB API YARDIMCILARI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def resolve_github_token() -> Optional[str]:
    tok = os.getenv("GITHUB_TOKEN")
    if tok:
        return tok
    for k in ("github_token", "GH_TOKEN", "GITHUB_TOKEN"):
        try:
            if k in st.secrets and st.secrets[k]:
                os.environ["GITHUB_TOKEN"] = str(st.secrets[k])
                return os.environ["GITHUB_TOKEN"]
        except Exception:
            pass
    return None

def gh_headers() -> dict:
    hdrs = {"Accept": "application/vnd.github+json"}
    tok = os.getenv("GITHUB_TOKEN")
    if tok:
        hdrs["Authorization"] = f"Bearer {tok}"
    return hdrs

@st.cache_data(show_spinner=True, ttl=15 * 60)
def fetch_latest_artifact_zip(owner: str, repo: str, artifact_name: str) -> bytes:
    base = f"https://api.github.com/repos/{owner}/{repo}/actions/artifacts"
    r = requests.get(base, headers=gh_headers(), timeout=30)
    r.raise_for_status()
    items = r.json().get("artifacts", [])
    cand = [a for a in items if a.get("name") == artifact_name and not a.get("expired", False)]
    if not cand:
        cand = [a for a in items if a.get("name","").startswith(artifact_name) and not a.get("expired", False)]
    if not cand:
        raise FileNotFoundError(f"Artifact bulunamadÄ±: {artifact_name}")
    cand.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
    url = cand[0].get("archive_download_url")
    if not url:
        raise RuntimeError("archive_download_url bulunamadÄ±")
    r2 = requests.get(url, headers=gh_headers(), timeout=60)
    r2.raise_for_status()
    return r2.content

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CSV OKU (HEDEF: risk_hourly_grid_full_labeled.csv)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REQUIRED_COLS = {
    "geoid", "hour_range", "risk_score", "risk_level",
    "expected_count",
    "top1_category","top1_prob","top1_expected",
    "top2_category","top2_prob","top2_expected",
    "top3_category","top3_prob","top3_expected",
}

def _normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip().lower() for c in df.columns]
    # GEOID eÅŸadlÄ±larÄ±
    if "geoid" not in df.columns:
        for alt in ("cell_id","geoid11","geoid_11","geoid10","geoid_10","id"):
            if alt in df.columns:
                df.rename(columns={alt:"geoid"}, inplace=True); break
    # Risk skoru eÅŸadlÄ±larÄ± (gerekirse)
    if "risk_score" not in df.columns:
        for alt in ("risk","score","prob","probability"):
            if alt in df.columns:
                df.rename(columns={alt:"risk_score"}, inplace=True); break
    # GEOID 11 haneye zorla
    if "geoid" in df.columns:
        df["geoid"] = (
            df["geoid"].astype(str)
            .str.replace(r"\D","", regex=True)
            .str.zfill(11)
        )
    # hour_range stringe zorla
    if "hour_range" in df.columns:
        df["hour_range"] = df["hour_range"].astype(str)
    return df

def _has_required_cols(df: pd.DataFrame) -> bool:
    return REQUIRED_COLS.issubset(set(df.columns))

@st.cache_data(show_spinner=True, ttl=15 * 60)
def load_hourly_csv(owner: str, repo: str, artifact_name: str, target_csv_name: str) -> pd.DataFrame:
    zip_bytes = fetch_latest_artifact_zip(owner, repo, artifact_name)
    with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:
        # Zip iÃ§inden isim/son ek eÅŸleÅŸmesi
        cand = [n for n in zf.namelist() if n.endswith("/"+target_csv_name) or n.endswith(target_csv_name)]
        if not cand:
            raise FileNotFoundError(f"Zip iÃ§inde {target_csv_name} bulunamadÄ±.")
        with zf.open(cand[0]) as f:
            df = pd.read_csv(f)
    df = _normalize_cols(df)
    if not _has_required_cols(df):
        missing = REQUIRED_COLS - set(df.columns)
        raise ValueError(f"CSV zorunlu kolonlarÄ± eksik: {', '.join(sorted(missing))}")
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GEOJSON (local â†’ artifact â†’ raw github)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=True, ttl=60 * 60)
def fetch_geojson_smart(path_local: str, path_in_zip: str, raw_owner: str, raw_repo: str) -> dict:
    # 1) Local
    try:
        if os.path.exists(path_local):
            with open(path_local, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    # 2) Artifact
    try:
        zip_bytes = fetch_latest_artifact_zip(OWNER, REPO, ARTIFACT_NAME)
        with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:
            memlist = zf.namelist()
            candidates = [n for n in memlist if n.endswith("/" + path_in_zip) or n.endswith(path_in_zip)]
            if candidates:
                with zf.open(candidates[0]) as f:
                    return json.load(io.TextIOWrapper(f, encoding="utf-8"))
    except Exception:
        pass
    # 3) Raw GitHub
    try:
        raw = f"https://raw.githubusercontent.com/{raw_owner}/{raw_repo}/main/{path_local}"
        r = requests.get(raw, timeout=30)
        if r.status_code == 200:
            return r.json()
    except Exception:
        pass
    return {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HOUR-RANGE SEÃ‡Ä°MÄ° (ANLIK) â€” sadece CSVâ€™deki etiketlerden biri
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_range_token(tok: str) -> Optional[tuple[int,int]]:
    if not isinstance(tok, str) or "-" not in tok:
        return None
    a, b = tok.split("-", 1)
    try:
        s = int(a.strip())
        e = int(b.strip())
        s = max(0, min(23, s))
        e = 24 if e == 24 else max(1, min(24, e))
        return (s, e)
    except Exception:
        return None

def hour_to_bucket(hour: int, candidates: Iterable[str]) -> Optional[str]:
    parsed = []
    for c in candidates:
        rng = parse_range_token(str(c))
        if rng:
            parsed.append((c, rng[0], rng[1]))
    # 1) DoÄŸrudan kapsama
    for label, s, e in parsed:
        if s <= hour < (e if e < 24 else 24):
            return label
    # 2) Sarma aralÄ±k
    for label, s, e in parsed:
        if s > e and (hour >= s or hour < e):
            return label
    # 3) Fallback
    if parsed:
        parsed.sort(key=lambda x: (abs(x[1]-hour), x[2]-x[1]))
        return parsed[0][0]
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RENKLER / TOOLTIP (risk_level CSVâ€™den â†’ TÃ¼rkÃ§e gÃ¶sterim)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# risk_level CSVâ€™de: low / medium / high / critical (Ã¶rneklerde bÃ¶yle gÃ¶rÃ¼nÃ¼yor)
# TÃ¼rkÃ§e gÃ¶sterim ve renk eÅŸlemeleri:
LEVEL_TR = {
    "low":      ("dÃ¼ÅŸÃ¼k riskli",   [56, 168, 0]),
    "medium":   ("orta riskli",    [255, 221, 0]),
    "high":     ("yÃ¼ksek riskli",  [255, 140, 0]),
    "critical": ("kritik riskli",  [160, 0, 0]),
    # Alternatif anahtarlar (TR/EN karÄ±ÅŸÄ±k gelirse)
    "dÃ¼ÅŸÃ¼k":    ("dÃ¼ÅŸÃ¼k riskli",   [56, 168, 0]),
    "orta":     ("orta riskli",    [255, 221, 0]),
    "yÃ¼ksek":   ("yÃ¼ksek riskli",  [255, 140, 0]),
    "kritik":   ("kritik riskli",  [160, 0, 0]),
}
DEFAULT_FILL = [220, 220, 220]

def inject_properties(geojson_dict: dict, df_hr: pd.DataFrame) -> dict:
    if not geojson_dict or df_hr.empty:
        return geojson_dict

    df = df_hr.copy()
    df["geoid"] = df["geoid"].astype(str).str.replace(r"\D","", regex=True).str.zfill(11)
    # risk_level â†’ lowercase
    df["risk_level"] = df["risk_level"].astype(str).str.strip().str.lower()

    # Tooltipâ€™te TÃ¼rkÃ§e gÃ¶sterim iÃ§in Ã¶n hesap
    def _fmt_prob(x):
        try: return f"{float(x):.3f}"
        except: return ""
    def _fmt_num(x):
        try: return f"{float(x):.3f}"
        except: return ""

    # Ä°ndeks: GEOID
    dmap = df.set_index("geoid")

    feats = geojson_dict.get("features", [])
    out = []
    for feat in feats:
        props = dict((feat.get("properties") or {}))
        raw = None
        for k in ("geoid","GEOID","cell_id","id"):
            if k in props:
                raw = props[k]; break
        if raw is None:
            for k, v in props.items():
                if "geoid" in str(k).lower():
                    raw = v; break
        key = str(raw) if raw is not None else ""
        key = "".join(ch for ch in key if ch.isdigit()).zfill(11)

        props.setdefault("display_id", str(raw or ""))

        if key in dmap.index:
            row = dmap.loc[key]
            # risk_score (0..1 arasÄ± varsayÄ±yoruz)
            try:
                rscore = float(row["risk_score"])
            except Exception:
                rscore = None
            props["risk_score_txt"] = (f"{min(max(rscore,0.0),0.999):.3f}" if rscore is not None else "")

            # risk_level (TR Ã§eviri + renk)
            lvl_key = str(row["risk_level"]).lower()
            tr_label, color = LEVEL_TR.get(lvl_key, ("bilinmiyor", DEFAULT_FILL))
            props["risk_level_tr"] = tr_label
            props["fill_color"] = color

            # expected_count ve Top1-Top3
            props["expected_count_txt"] = _fmt_num(row.get("expected_count", ""))
            for i in (1,2,3):
                c = row.get(f"top{i}_category", "")
                p = row.get(f"top{i}_prob", "")
                e = row.get(f"top{i}_expected", "")
                props[f"top{i}_category"] = (str(c) if pd.notna(c) and str(c).strip() else "")
                props[f"top{i}_prob_txt"]  = _fmt_prob(p)
                props[f"top{i}_exp_txt"]   = _fmt_num(e)
        else:
            props.setdefault("risk_level_tr","veri yok")
            props.setdefault("risk_score_txt","")
            props.setdefault("expected_count_txt","")
            props.setdefault("fill_color", DEFAULT_FILL)

        out.append({**feat, "properties": props})
    return {**geojson_dict, "features": out}

def make_map(geojson_enriched: dict):
    if not geojson_enriched:
        st.info("HaritayÄ± gÃ¶rmek iÃ§in GeoJSON bulunamadÄ±.")
        return
    layer = pdk.Layer(
        "GeoJsonLayer",
        geojson_enriched,
        stroked=True,
        get_line_color=[80, 80, 80],
        line_width_min_pixels=0.5,
        filled=True,
        get_fill_color="properties.fill_color",
        pickable=True,
        opacity=0.65,
    )
    # TR aÃ§Ä±klamalÄ± tooltip
    tooltip = {
        "html": (
            "<b>GEOID:</b> {display_id}"
            "<br/><b>Risk dÃ¼zeyi:</b> {risk_level_tr}"
            "<br/><b>Risk skoru (0-1):</b> {risk_score_txt}"
            "<br/><b>Beklenen toplam olay (bu saat dilimi):</b> {expected_count_txt}"
            "<hr style='opacity:0.3'/>"
            "<b>En olasÄ± suÃ§ tipleri</b>"
            "<br/>1) {top1_category} â€” olasÄ±lÄ±k: {top1_prob_txt} â€” beklenen: {top1_exp_txt}"
            "<br/>2) {top2_category} â€” olasÄ±lÄ±k: {top2_prob_txt} â€” beklenen: {top2_exp_txt}"
            "<br/>3) {top3_category} â€” olasÄ±lÄ±k: {top3_prob_txt} â€” beklenen: {top3_exp_txt}"
        ),
        "style": {"backgroundColor": "#262730", "color": "white"},
    }
    deck = pdk.Deck(
        layers=[layer],
        initial_view_state=pdk.ViewState(latitude=37.7749, longitude=-122.4194, zoom=10),
        map_style="light",
        tooltip=tooltip,
    )
    st.pydeck_chart(deck, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AKIÅž: Token â†’ CSVâ€™yi yÃ¼kle â†’ anlÄ±k hour_range â†’ filtrele â†’ GeoJSON zenginleÅŸtir â†’ HARÄ°TA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not resolve_github_token():
    st.error("GitHub token yok. `st.secrets['github_token']` veya GITHUB_TOKEN env ayarlayÄ±n.")
    st.stop()

try:
    df_all = load_hourly_csv(OWNER, REPO, ARTIFACT_NAME, CSV_TARGET_NAME)
except Exception as e:
    st.error(f"Artifact/CSV okunamadÄ±: {e}")
    st.stop()

# Mevcut hour_range adaylarÄ± (CSVâ€™den)
hour_opts = sorted([str(x) for x in df_all["hour_range"].dropna().astype(str).unique()])

# SF saatine gÃ¶re anlÄ±k hour_range
try:
    tz = ZoneInfo(TARGET_TZ)
except Exception:
    tz = ZoneInfo("America/Los_Angeles")

now_local = datetime.now(tz)
current_hour = now_local.hour
selected_hr = hour_to_bucket(current_hour, hour_opts) or (hour_opts[0] if hour_opts else None)

# BaÅŸlÄ±k altÄ± kÃ¼Ã§Ã¼k bilgi
st.caption(f"SF yerel zamanÄ±: **{now_local.strftime('%Y-%m-%d %H:%M')} ({tz.key})** â€” "
           f"seÃ§ilen saat dilimi: **{selected_hr}**")

if not selected_hr:
    st.info("Bu veri kÃ¼mesinde hour_range bulunamadÄ±.")
    st.stop()

# YalnÄ±zca ANLIK dilimi gÃ¶ster
df_hr = df_all[df_all["hour_range"].astype(str) == str(selected_hr)].copy()

# HÄ±zlÄ± Ã¶zet
c1, c2, c3 = st.columns(3)
c1.metric("GEOID sayÄ±sÄ±", f"{df_hr['geoid'].nunique():,}")
c2.metric("Risk skoru medyanÄ±", f"{df_hr['risk_score'].median():.3f}" if not df_hr.empty else "â€”")
c3.metric("En yÃ¼ksek skor", f"{df_hr['risk_score'].max():.3f}" if not df_hr.empty else "â€”")

# GeoJSON â†’ enrich â†’ harita
gj = fetch_geojson_smart(
    GEOJSON_PATH_LOCAL_DEFAULT,
    GEOJSON_PATH_LOCAL_DEFAULT,
    RAW_GEOJSON_OWNER,
    RAW_GEOJSON_REPO
)
enriched = inject_properties(gj, df_hr)
make_map(enriched)

# Alt bilgi / rozet
show_last_update_badge(data_upto=None, model_version=MODEL_VERSION, last_train=MODEL_LAST_TRAIN)
