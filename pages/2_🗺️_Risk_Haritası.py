# pages/2_ğŸ—ºï¸_Risk_HaritasÄ±.py
import io, os, json, zipfile
from typing import Optional
from datetime import date
import pandas as pd
import streamlit as st
import pydeck as pdk
import requests

from components.last_update import show_last_update_badge
from components.meta import MODEL_VERSION, MODEL_LAST_TRAIN

st.set_page_config(page_title="ğŸ—ºï¸ Risk HaritasÄ± (GÃ¼nlÃ¼k)", layout="wide")
st.title("ğŸ•’ AnlÄ±k SuÃ§ Risk HaritasÄ±")
st.markdown(
    "<p style='font-size:14px; font-style:italic;'>Bu harita, en gÃ¼ncel veriler Ã¼zerinden her GEOID bazÄ±nda 24 saat iÃ§erisinde suÃ§ gerÃ§ekleÅŸme olasÄ±lÄ±klarÄ±nÄ± gÃ¶stermektedir. Harita, model tarafÄ±ndan son gÃ¼ncellenen tahmin skorlarÄ± Ã¼zerinden oluÅŸturulmuÅŸtur. GerÃ§ek suÃ§ verileriyle birebir eÅŸleÅŸmeyebilir.</p>",
    unsafe_allow_html=True
)

# â”€â”€ Ayarlar / varsayÄ±lanlar
cfg = getattr(st, "secrets", {}) if hasattr(st, "secrets") else {}
# EÄŸer DATA_REPO verilmiÅŸse OWNER/REPOâ€™yu oradan ayÄ±kla
DATA_REPO = cfg.get("DATA_REPO", os.getenv("DATA_REPO", "cem5113/crime_prediction_data"))
DATA_BRANCH = cfg.get("DATA_BRANCH", os.getenv("DATA_BRANCH", "main"))
if "/" in DATA_REPO:
    OWNER, REPO = DATA_REPO.split("/", 1)
else:
    OWNER, REPO = cfg.get("artifact_owner", "cem5113"), cfg.get("artifact_repo", "crime_prediction_data")

ARTIFACT_NAME = cfg.get("artifact_name", "sf-crime-parquet")
EXPECTED_PARQUET = "risk_hourly.parquet"

# Release fallback iÃ§in (public)
ASSET_ZIP_1 = cfg.get("ASSET_ZIP_1", os.getenv("ASSET_ZIP_1", "sf-crime-parquet.zip"))
ASSET_DIR_1 = cfg.get("ASSET_DIR_1", os.getenv("ASSET_DIR_1", "sf-crime-parquet"))

GEOJSON_PATH_LOCAL_DEFAULT = cfg.get("geojson_path", "data/sf_cells.geojson")
RAW_GEOJSON_OWNER = cfg.get("geojson_owner", "cem5113")
RAW_GEOJSON_REPO = cfg.get("geojson_repo", "crimepredict")

# â”€â”€ YardÄ±mcÄ±lar: token Ã§Ã¶zÃ¼mleme, baÅŸlÄ±klar, maskeleme
def _secret_lookup_in_secrets(keys=("GITHUB_TOKEN", "GH_TOKEN", "github_token")) -> Optional[str]:
    try:
        sec = getattr(st, "secrets", None)
        if not sec:
            return None

        # 1) dÃ¼z anahtarlar
        for k in keys:
            v = sec.get(k)
            if v:
                v = str(v).strip()
                if v:
                    return v
        # 2) olasÄ± alt sÃ¶zlÃ¼kler
        for bucket in ("github", "tokens", "secrets", "config"):
            sub = sec.get(bucket)
            if isinstance(sub, dict):
                for k in list(keys) + [k.lower() for k in keys]:
                    v = sub.get(k)
                    if v:
                        v = str(v).strip()
                        if v:
                            return v
    except Exception:
        pass
    return None

def resolve_github_token() -> Optional[str]:
    tok = (os.getenv("GITHUB_TOKEN")
           or os.getenv("GH_TOKEN")
           or os.getenv("github_token"))
    if not tok:
        tok = _secret_lookup_in_secrets()
    if tok:
        tok = str(tok).strip()
        if tok:
            os.environ["GITHUB_TOKEN"] = tok  # tek kaynak
            return tok
    return None

def gh_headers() -> dict:
    hdrs = {"Accept": "application/vnd.github+json"}
    tok = os.getenv("GITHUB_TOKEN") or resolve_github_token()
    if tok:
        hdrs["Authorization"] = f"Bearer {tok}"
    return hdrs

def _mask(tok: Optional[str]) -> str:
    if not tok: return "â€”"
    t = str(tok)
    if len(t) <= 12: return t[:3] + "â€¦" + t[-2:]
    return t[:6] + "â€¦" + t[-4:]

# â”€â”€ Artifact / Release indirme
@st.cache_data(show_spinner=True, ttl=15*60)
def fetch_latest_artifact_zip(owner: str, repo: str, artifact_name: str) -> bytes:
    """
    1) Token varsa: Actions Artifacts (en gÃ¼ncel).
    2) Yoksa veya baÅŸarÄ±sÄ±zsa: Releases/latest/download/{ASSET_ZIP_1} (public).
    """
    tok = resolve_github_token()
    if tok:
        try:
            base = f"https://api.github.com/repos/{owner}/{repo}/actions/artifacts"
            r = requests.get(base, headers=gh_headers(), timeout=30)
            r.raise_for_status()
            items = r.json().get("artifacts", [])
            cand = [a for a in items if a.get("name") == artifact_name and not a.get("expired", False)]
            if cand:
                cand.sort(key=lambda x: x.get("updated_at", "") or "", reverse=True)
                url = cand[0].get("archive_download_url")
                if url:
                    r2 = requests.get(url, headers=gh_headers(), timeout=60)
                    r2.raise_for_status()
                    return r2.content
        except Exception as e:
            st.warning(f"Artifact API eriÅŸimi baÅŸarÄ±sÄ±z; Release fallback deneniyorâ€¦ ({e})")

    # Release fallback (public)
    rel_url = f"https://github.com/{owner}/{repo}/releases/latest/download/{ASSET_ZIP_1}"
    r3 = requests.get(rel_url, timeout=60)
    if r3.status_code == 200 and r3.content:
        return r3.content
    raise FileNotFoundError(
        f"Ä°ndirilemedi: Artifact API ya da Release asset (denenen: {rel_url})."
    )

@st.cache_data(show_spinner=True, ttl=15*60)
def read_risk_from_artifact(owner: str, repo: str, artifact_name: str) -> pd.DataFrame:
    zip_bytes = fetch_latest_artifact_zip(owner, repo, artifact_name)
    with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:
        memlist = zf.namelist()

        # Ã–nce doÄŸrudan EXPECTED_PARQUET (risk_hourly.parquet)
        matches = [n for n in memlist if n.endswith("/" + EXPECTED_PARQUET) or n.endswith(EXPECTED_PARQUET)]

        # Bulunamazsa ASSET_DIR_1 altÄ±nda ara (Ã¶r. sf-crime-parquet/risk_hourly.parquet)
        if not matches and ASSET_DIR_1:
            matches = [n for n in memlist if n.endswith(f"{ASSET_DIR_1}/{EXPECTED_PARQUET}")]

        if not matches:
            sample = ", ".join(memlist[:10])
            raise FileNotFoundError(f"Zip iÃ§inde {EXPECTED_PARQUET} bulunamadÄ±. Ã–rnek iÃ§erik: [{sample}]")

        with zf.open(matches[0]) as f:
            df = pd.read_parquet(f)

    # kolon normalizasyonu
    df.columns = [c.strip().lower() for c in df.columns]

    # risk_score esnek eÅŸle
    if "risk_score" not in df.columns:
        for alt in ("risk", "score", "prob", "probability"):
            if alt in df.columns:
                df = df.rename(columns={alt: "risk_score"})
                break
    if "risk_score" not in df.columns:
        raise ValueError("Beklenen kolon yok: risk_score")

    # geoid tÃ¼retme
    if "geoid" not in df.columns:
        for alt in ("cell_id", "geoid10", "geoid11", "geoid_10", "geoid_11", "id"):
            if alt in df.columns:
                df["geoid"] = df[alt]
                break
    if "geoid" not in df.columns:
        raise ValueError("Beklenen kolon yok: geoid / cell_id")

    df["geoid"] = (
        df["geoid"].astype(str)
        .str.replace(r"\D", "", regex=True)
        .str.zfill(11)
    )

    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"]).dt.date
    else:
        raise ValueError("Beklenen kolon yok: date")

    return df

# â”€â”€ DÃ¶nÃ¼ÅŸÃ¼mler ve harita
def daily_average(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    needed = {"geoid", "date", "risk_score"}
    missing = needed - set(df.columns)
    if missing:
        raise ValueError(f"Eksik kolon(lar): {', '.join(sorted(missing))}")
    return (
        df.groupby(["geoid", "date"], as_index=False)["risk_score"]
        .mean()
        .rename(columns={"risk_score": "risk_score_daily"})
    )

def only_digits(s: str) -> str:
    return "".join(ch for ch in str(s) if ch.isdigit())

def classify_quantiles(daily_df: pd.DataFrame, day: date) -> pd.DataFrame:
    one = daily_df[daily_df["date"] == day].copy()
    if one.empty:
        return one
    q25, q50, q75 = one["risk_score_daily"].quantile([0.25, 0.5, 0.75]).tolist()

    def lab(x: float) -> str:
        if x <= q25: return "dÃ¼ÅŸÃ¼k riskli"
        elif x <= q50: return "orta riskli"
        elif x <= q75: return "riskli"
        return "yÃ¼ksek riskli"

    one["risk_level"] = one["risk_score_daily"].apply(lab)
    one["q25"], one["q50"], one["q75"] = q25, q50, q75
    return one

@st.cache_data(show_spinner=True, ttl=60*60)
def fetch_geojson_smart(path_local: str, path_in_zip: str, raw_owner: str, raw_repo: str) -> dict:
    # 1) Local
    try:
        if os.path.exists(path_local):
            with open(path_local, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    # 2) Artifact (varsa)
    try:
        zip_bytes = fetch_latest_artifact_zip(OWNER, REPO, ARTIFACT_NAME)
        with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:
            memlist = zf.namelist()
            candidates = [n for n in memlist if n.endswith("/" + path_in_zip) or n.endswith(path_in_zip)]
            if candidates:
                with zf.open(candidates[0]) as f:
                    return json.load(io.TextIOWrapper(f, encoding="utf-8"))
    except Exception:
        pass
    # 3) Raw GitHub (public)
    try:
        raw = f"https://raw.githubusercontent.com/{raw_owner}/{raw_repo}/main/{path_local}"
        r = requests.get(raw, timeout=30)
        if r.status_code == 200:
            return r.json()
    except Exception:
        pass
    return {}

def inject_properties(geojson_dict: dict, day_df: pd.DataFrame) -> dict:
    if not geojson_dict or day_df.empty:
        return geojson_dict
    df = day_df.copy()
    df["geoid_digits"] = df["geoid"].astype(str).str.replace(r"\D", "", regex=True).str.zfill(11)
    dmap = (
        df.groupby("geoid_digits", as_index=True)["risk_score_daily"]
        .mean()
        .to_frame()
        .rename_axis("match_key")
    )
    feats = geojson_dict.get("features", [])
    q25 = float(df["risk_score_daily"].quantile(0.25))
    q50 = float(df["risk_score_daily"].quantile(0.50))
    q75 = float(df["risk_score_daily"].quantile(0.75))
    EPS = 1e-12
    COLOR_MAP = {
        "Ã§ok dÃ¼ÅŸÃ¼k riskli": [200, 200, 200],
        "dÃ¼ÅŸÃ¼k riskli":     [56, 168, 0],
        "orta riskli":      [255, 221, 0],
        "riskli":           [255, 140, 0],
        "yÃ¼ksek riskli":    [204, 0, 0],
    }
    out = []
    for feat in feats:
        props = (feat.get("properties") or {}).copy()
        raw = next((props[k] for k in ("geoid", "GEOID", "cell_id", "id") if k in props), None)
        if raw is None:
            for k, v in props.items():
                if "geoid" in str(k).lower():
                    raw = v
                    break
        props.setdefault("display_id", str(raw or ""))
        key = only_digits(raw)[:11] if raw is not None else ""
        lvl = None
        if key and key in dmap.index:
            val = float(dmap.loc[key, "risk_score_daily"])
            props["risk_score_daily"] = val
            disp = min(val, 0.999)
            props["risk_score_txt"] = f"{disp:.3f}"
            if abs(val) <= EPS: lvl = "Ã§ok dÃ¼ÅŸÃ¼k riskli"
            elif val <= q25:   lvl = "dÃ¼ÅŸÃ¼k riskli"
            elif val <= q50:   lvl = "orta riskli"
            elif val <= q75:   lvl = "riskli"
            else:              lvl = "yÃ¼ksek riskli"
        if lvl is None:
            lvl = props.get("risk_level", "Ã§ok dÃ¼ÅŸÃ¼k riskli")
        props["risk_level"] = lvl
        props["fill_color"] = COLOR_MAP.get(lvl, [220, 220, 220])
        out.append({**feat, "properties": props})
    return {**geojson_dict, "features": out}

def make_map(geojson_enriched: dict):
    if not geojson_enriched:
        st.info("HaritayÄ± gÃ¶rmek iÃ§in GeoJSON bulunamadÄ±.")
        return
    layer = pdk.Layer(
        "GeoJsonLayer",
        geojson_enriched,
        stroked=True,
        get_line_color=[80, 80, 80],
        line_width_min_pixels=0.5,
        filled=True,
        get_fill_color="properties.fill_color",
        pickable=True,
        opacity=0.65,
    )
    tooltip = {
        "html": "<b>GEOID:</b> {display_id}<br/><b>Risk:</b> {risk_level}<br/><b>Skor:</b> {risk_score_txt}",
        "style": {"backgroundColor": "#262730", "color": "white"},
    }
    deck = pdk.Deck(
        layers=[layer],
        initial_view_state=pdk.ViewState(latitude=37.7749, longitude=-122.4194, zoom=10),
        map_style="light",
        tooltip=tooltip,
    )
    st.pydeck_chart(deck, use_container_width=True)

# â”€â”€ UI / Diagnostik
TOKEN = resolve_github_token()

st.sidebar.header("GitHub BaÄŸlantÄ±")
with st.sidebar.expander("ğŸ” Token Durumu", expanded=TOKEN is None):
    env_tok = os.getenv("GITHUB_TOKEN")
    st.write("ENV GITHUB_TOKEN:", "âœ…" if env_tok else "âŒ")
    try:
        sec = getattr(st, "secrets", None)
        s_flat = bool(sec and any(k in sec and sec[k] for k in ("GITHUB_TOKEN","GH_TOKEN","github_token")))
        s_nested = bool(
            sec and any(isinstance(sec.get(b), dict) and any(x in sec[b] for x in ("GITHUB_TOKEN","GH_TOKEN","github_token"))
                        for b in ("github","tokens","secrets","config"))
        )
        st.write("secrets (dÃ¼z):", "âœ…" if s_flat else "âŒ")
        st.write("secrets (iÃ§ iÃ§e):", "âœ…" if s_nested else "âŒ")
        st.write("Token (maskeli):", _mask(env_tok))
    except Exception:
        st.write("secrets eriÅŸimi: âŒ (lokal olabilir)")

refresh = st.sidebar.button("Veriyi Yenile (artefact/asset)")
if refresh:
    fetch_latest_artifact_zip.clear()
    read_risk_from_artifact.clear()
    fetch_geojson_smart.clear()

# â”€â”€ Veri yÃ¼kleme
try:
    if not TOKEN:
        st.warning("GitHub token bulunamadÄ± â€” Actions artifact yerine Release yedeÄŸi deneniyorâ€¦")
    risk_df = read_risk_from_artifact(OWNER, REPO, ARTIFACT_NAME)
except Exception as e:
    st.error(f"Veri indirilemedi: {e}")
    st.stop()

# â”€â”€ GÃ¼nlÃ¼k ortalama ve harita
risk_daily = daily_average(risk_df)
dates = sorted(risk_daily["date"].unique())
sel_date = st.sidebar.selectbox("GÃ¼n seÃ§in", dates, index=len(dates) - 1, format_func=str) if dates else None
one_day = classify_quantiles(risk_daily, sel_date) if sel_date else pd.DataFrame()

if not one_day.empty:
    q25 = one_day['q25'].iloc[0] * 100
    q50 = one_day['q50'].iloc[0] * 100
    q75 = one_day['q75'].iloc[0] * 100
    st.markdown(
        f"""
        <div style="font-size:17px; margin-top:10px; line-height:1.6;">
            ğŸŸ¢ <b>DÃ¼ÅŸÃ¼k Riskli:</b> &lt; %{q25:.2f}<br>
            ğŸŸ¡ <b>Orta Riskli:</b> &gt; %{q25:.2f}<br>
            ğŸŸ  <b>Riskli:</b> &gt; %{q50:.2f}<br>
            ğŸ”´ <b>YÃ¼ksek Riskli:</b> &gt; %{q75:.2f}
        </div>
        <div style="font-size:13px; font-style:italic; color:#666; margin-top:8px;">
            Bu sÄ±nÄ±flandÄ±rma, GEOID alanlarÄ±nÄ± dÃ¶rt risk seviyesine ayÄ±rmak iÃ§in belirlenen gÃ¼nlÃ¼k risk skorlarÄ±ndan elde edilen deÄŸiÅŸken eÅŸiklere dayanmaktadÄ±r.
        </div>
        """,
        unsafe_allow_html=True
    )
    gj = fetch_geojson_smart(
        GEOJSON_PATH_LOCAL_DEFAULT,
        GEOJSON_PATH_LOCAL_DEFAULT,
        RAW_GEOJSON_OWNER,
        RAW_GEOJSON_REPO
    )
    enriched = inject_properties(gj, one_day)
    make_map(enriched)
else:
    st.info("SeÃ§ili tarih iÃ§in veri yok.")

show_last_update_badge(data_upto=None, model_version=MODEL_VERSION, last_train=MODEL_LAST_TRAIN)
